{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ssGm3bK7osY"
   },
   "source": [
    "# Neural Networks - Lab 1\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Ομάδα Α61\n",
    "### Αβδελάς Λεωνίδας 03113182\n",
    "### Σκούρας Κωνσταντίνος 03113096\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uti-XH4JBF9B"
   },
   "source": [
    "# Dataset Description\n",
    "\n",
    "This is a data set containing **1079 documents** of free text business descriptions of Brazilian companies **categorized into a subset of 9 categories cataloged** in a table called National Classification of Economic Activities (Classification Nacional de Atividade Economicas - CNAE)\n",
    "\n",
    "The original texts were pre-processed to obtain the current data set: initially, it was kept only letters and then it was removed prepositions of the texts. Next, the words were transformed to their canonical form. Finally, **each document was represented as a vector, where the weight of each word is its frequency in the document. This data set is highly sparse (99.22% of the matrix is filled with zeros).**\n",
    "\n",
    "Number of Instances: 1079\n",
    "\n",
    "Number of Attributes: 857 (1 category, 856 word frequency)\n",
    "\n",
    "Attribute Information:\n",
    "   1 category: range 1 - 9 (integer)\n",
    "   2 - 857. word frequency: (integer)\n",
    "\n",
    "Missing Attribute Values: None\n",
    "\n",
    "Class Distribution: the categories are equally distribuited. (120 instances in each of nine categories)\n",
    "\n",
    "Summary Statistics:\n",
    "                 \n",
    " Min   Max   Mean    SD\n",
    "\n",
    "0  4   0.0082 0.0948   (word frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "jCBuu4Ms-uRu",
    "outputId": "4b68ce19-17b8-4d04-9277-08ecb7710313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-12-12 21:40:20--  http://archive.ics.uci.edu/ml/machine-learning-databases/00233/CNAE-9.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.249\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.249|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1851120 (1.8M) [text/plain]\n",
      "Saving to: ‘CNAE-9.data’\n",
      "\n",
      "CNAE-9.data         100%[===================>]   1.76M  2.10MB/s    in 0.8s    \n",
      "\n",
      "2018-12-12 21:40:21 (2.10 MB/s) - ‘CNAE-9.data’ saved [1851120/1851120]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/00233/CNAE-9.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ztoBJzNnHAku",
    "outputId": "25a32e5a-5247-4bd0-a312-ba74b188094b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNAE-9.data  sample_data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wPumk_mBHJ_1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1969
    },
    "colab_type": "code",
    "id": "KPWTJ9_pHSLP",
    "outputId": "a653dd43-1093-4b51-d6e7-b9cf85d49d75"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>...</th>\n",
       "      <th>0.843</th>\n",
       "      <th>0.844</th>\n",
       "      <th>0.845</th>\n",
       "      <th>0.846</th>\n",
       "      <th>0.847</th>\n",
       "      <th>0.848</th>\n",
       "      <th>0.849</th>\n",
       "      <th>0.850</th>\n",
       "      <th>0.851</th>\n",
       "      <th>0.852</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1079 rows × 857 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...    0.843  0.844  \\\n",
       "0     2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1     3  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "2     4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "3     5  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "4     6  0    0    1    0    0    0    0    0    0  ...        0      0   \n",
       "5     7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "6     8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "7     9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "8     1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "9     2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "10    3  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "11    4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "12    5  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "13    6  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "14    7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "15    8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "16    9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "17    1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "18    2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "19    3  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "20    4  0    0    0    0    0    0    1    0    0  ...        0      0   \n",
       "21    5  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "22    6  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "23    7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "24    8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "25    9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "26    1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "27    2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "28    3  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "29    4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "...  .. ..  ...  ...  ...  ...  ...  ...  ...  ...  ...      ...    ...   \n",
       "1049  7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1050  8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1051  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1052  1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1053  2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1054  3  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1055  4  0    0    0    0    0    0    1    0    0  ...        0      0   \n",
       "1056  5  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1057  6  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1058  7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1059  8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1060  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1061  1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1062  2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1063  3  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1064  4  0    0    0    0    0    0    1    0    0  ...        0      0   \n",
       "1065  5  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1066  6  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1067  7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1068  8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1069  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1070  1  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1071  2  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1072  3  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1073  4  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1074  5  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1075  6  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1076  7  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1077  8  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1078  9  0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "\n",
       "      0.845  0.846  0.847  0.848  0.849  0.850  0.851  0.852  \n",
       "0         0      0      0      0      0      0      0      0  \n",
       "1         0      0      0      0      0      0      0      0  \n",
       "2         0      0      0      0      0      0      0      0  \n",
       "3         0      0      0      0      0      0      0      0  \n",
       "4         0      0      0      0      0      0      0      0  \n",
       "5         0      0      0      0      0      0      0      0  \n",
       "6         0      0      0      0      0      0      0      0  \n",
       "7         0      0      0      0      0      0      0      0  \n",
       "8         0      0      0      0      0      0      0      0  \n",
       "9         0      0      0      0      0      0      0      0  \n",
       "10        0      0      0      0      0      0      0      0  \n",
       "11        0      0      0      0      0      0      0      0  \n",
       "12        0      0      0      0      0      0      0      0  \n",
       "13        0      0      0      0      0      0      0      0  \n",
       "14        0      0      0      0      0      0      0      0  \n",
       "15        0      0      0      0      0      0      0      0  \n",
       "16        0      0      0      0      0      0      0      0  \n",
       "17        0      0      0      0      0      0      0      0  \n",
       "18        0      0      0      0      0      0      0      0  \n",
       "19        0      0      0      0      0      0      0      0  \n",
       "20        0      0      0      0      0      0      0      0  \n",
       "21        0      0      1      0      0      0      0      0  \n",
       "22        0      0      0      0      0      0      0      0  \n",
       "23        0      0      0      0      0      0      0      0  \n",
       "24        0      0      0      0      0      0      0      0  \n",
       "25        0      0      0      0      0      0      0      0  \n",
       "26        0      0      0      0      0      0      0      0  \n",
       "27        0      0      0      0      0      0      0      0  \n",
       "28        0      0      0      0      0      0      0      0  \n",
       "29        0      0      0      0      0      0      0      0  \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "1049      0      0      0      0      0      0      0      0  \n",
       "1050      0      0      0      0      0      0      0      0  \n",
       "1051      0      0      0      0      0      0      0      0  \n",
       "1052      0      0      0      0      0      0      0      0  \n",
       "1053      0      0      0      0      0      0      0      0  \n",
       "1054      0      0      0      0      0      0      0      0  \n",
       "1055      0      0      0      0      0      0      0      0  \n",
       "1056      0      0      0      0      0      0      0      0  \n",
       "1057      0      0      0      0      0      0      0      0  \n",
       "1058      0      0      0      0      0      0      0      0  \n",
       "1059      0      0      0      0      0      0      0      0  \n",
       "1060      0      0      0      0      0      0      0      0  \n",
       "1061      0      0      0      0      0      0      0      0  \n",
       "1062      0      0      0      0      0      0      0      0  \n",
       "1063      0      0      0      0      0      0      0      0  \n",
       "1064      0      0      0      0      0      0      0      0  \n",
       "1065      0      0      1      0      0      0      0      0  \n",
       "1066      0      0      0      0      0      0      0      0  \n",
       "1067      0      0      0      0      0      0      0      0  \n",
       "1068      0      0      0      0      0      0      0      0  \n",
       "1069      0      0      0      0      0      0      0      0  \n",
       "1070      0      0      0      0      0      0      0      0  \n",
       "1071      0      0      0      0      0      0      0      0  \n",
       "1072      0      0      0      0      0      0      0      0  \n",
       "1073      0      0      0      0      0      0      1      0  \n",
       "1074      0      0      1      0      0      0      0      0  \n",
       "1075      0      0      0      0      0      0      0      0  \n",
       "1076      0      0      0      0      0      0      0      0  \n",
       "1077      0      0      0      0      0      0      0      0  \n",
       "1078      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[1079 rows x 857 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnae_df = pd.read_csv('CNAE-9.data')\n",
    "display(cnae_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Efpchl4yZdlo",
    "outputId": "1edd9b38-d396-4742-d0ec-ddac666d0510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 6 7 8 9]\n",
      "[2 3 4 ... 7 8 9]\n",
      "(1079,)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "label_names = np.arange(1,10) # Our categories are integers in the range 1 - 9 \n",
    "labels = cnae_df['1'].values # Get the categories values, of each one of our 1078 samples. They are located in column named 1\n",
    "print (label_names)\n",
    "print (labels)\n",
    "print (labels.shape)\n",
    "print (labels.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1649
    },
    "colab_type": "code",
    "id": "4IwaKmq9IHfg",
    "outputId": "5a768c43-8e66-488d-b986-8a097c51ef52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0' '0.1' '0.2' '0.3' '0.4' '0.5' '0.6' '0.7' '0.8' '0.9' '0.10' '0.11'\n",
      " '0.12' '0.13' '0.14' '0.15' '0.16' '0.17' '0.18' '0.19' '0.20' '0.21'\n",
      " '0.22' '0.23' '0.24' '0.25' '0.26' '0.27' '0.28' '0.29' '0.30' '0.31'\n",
      " '0.32' '0.33' '0.34' '0.35' '0.36' '0.37' '0.38' '0.39' '0.40' '0.41'\n",
      " '0.42' '0.43' '0.44' '0.45' '0.46' '0.47' '0.48' '0.49' '0.50' '0.51'\n",
      " '0.52' '0.53' '0.54' '0.55' '0.56' '0.57' '0.58' '0.59' '0.60' '0.61'\n",
      " '0.62' '0.63' '0.64' '0.65' '0.66' '0.67' '0.68' '0.69' '0.70' '0.71'\n",
      " '0.72' '0.73' '0.74' '0.75' '0.76' '0.77' '0.78' '0.79' '0.80' '0.81'\n",
      " '0.82' '0.83' '0.84' '0.85' '0.86' '0.87' '0.88' '0.89' '0.90' '0.91'\n",
      " '0.92' '0.93' '0.94' '0.95' '0.96' '0.97' '0.98' '0.99' '0.100' '0.101'\n",
      " '0.102' '0.103' '0.104' '0.105' '0.106' '0.107' '0.108' '0.109' '0.110'\n",
      " '0.111' '0.112' '0.113' '0.114' '0.115' '0.116' '0.117' '0.118' '0.119'\n",
      " '0.120' '0.121' '0.122' '0.123' '0.124' '0.125' '0.126' '0.127' '0.128'\n",
      " '0.129' '0.130' '0.131' '0.132' '0.133' '0.134' '0.135' '0.136' '0.137'\n",
      " '0.138' '0.139' '0.140' '0.141' '0.142' '0.143' '0.144' '0.145' '0.146'\n",
      " '0.147' '0.148' '0.149' '0.150' '0.151' '0.152' '0.153' '0.154' '0.155'\n",
      " '0.156' '0.157' '0.158' '0.159' '0.160' '0.161' '0.162' '0.163' '0.164'\n",
      " '0.165' '0.166' '0.167' '0.168' '0.169' '0.170' '0.171' '0.172' '0.173'\n",
      " '0.174' '0.175' '0.176' '0.177' '0.178' '0.179' '0.180' '0.181' '0.182'\n",
      " '0.183' '0.184' '0.185' '0.186' '0.187' '0.188' '0.189' '0.190' '0.191'\n",
      " '0.192' '0.193' '0.194' '0.195' '0.196' '0.197' '0.198' '0.199' '0.200'\n",
      " '0.201' '0.202' '0.203' '0.204' '0.205' '0.206' '0.207' '0.208' '0.209'\n",
      " '0.210' '0.211' '0.212' '0.213' '0.214' '0.215' '0.216' '0.217' '0.218'\n",
      " '0.219' '0.220' '0.221' '0.222' '0.223' '0.224' '0.225' '0.226' '0.227'\n",
      " '0.228' '0.229' '0.230' '0.231' '0.232' '0.233' '0.234' '0.235' '0.236'\n",
      " '0.237' '0.238' '0.239' '0.240' '0.241' '0.242' '0.243' '0.244' '0.245'\n",
      " '0.246' '0.247' '0.248' '0.249' '0.250' '0.251' '0.252' '0.253' '0.254'\n",
      " '0.255' '0.256' '0.257' '0.258' '0.259' '0.260' '0.261' '0.262' '0.263'\n",
      " '0.264' '0.265' '0.266' '0.267' '0.268' '0.269' '0.270' '0.271' '0.272'\n",
      " '0.273' '0.274' '0.275' '0.276' '0.277' '0.278' '0.279' '0.280' '0.281'\n",
      " '0.282' '0.283' '0.284' '0.285' '0.286' '0.287' '0.288' '0.289' '0.290'\n",
      " '0.291' '0.292' '0.293' '0.294' '0.295' '0.296' '0.297' '0.298' '0.299'\n",
      " '0.300' '0.301' '0.302' '0.303' '0.304' '0.305' '0.306' '0.307' '0.308'\n",
      " '0.309' '0.310' '0.311' '0.312' '0.313' '0.314' '0.315' '0.316' '0.317'\n",
      " '0.318' '0.319' '0.320' '0.321' '0.322' '0.323' '0.324' '0.325' '0.326'\n",
      " '0.327' '0.328' '0.329' '0.330' '0.331' '0.332' '1.1' '0.333' '0.334'\n",
      " '0.335' '0.336' '0.337' '0.338' '0.339' '0.340' '0.341' '0.342' '0.343'\n",
      " '0.344' '0.345' '0.346' '0.347' '0.348' '0.349' '0.350' '0.351' '0.352'\n",
      " '0.353' '0.354' '0.355' '0.356' '0.357' '0.358' '0.359' '0.360' '0.361'\n",
      " '0.362' '0.363' '0.364' '0.365' '0.366' '0.367' '0.368' '0.369' '0.370'\n",
      " '0.371' '0.372' '0.373' '0.374' '0.375' '0.376' '0.377' '0.378' '0.379'\n",
      " '0.380' '0.381' '0.382' '0.383' '0.384' '0.385' '0.386' '0.387' '0.388'\n",
      " '0.389' '0.390' '0.391' '0.392' '0.393' '0.394' '0.395' '0.396' '0.397'\n",
      " '0.398' '0.399' '0.400' '0.401' '0.402' '0.403' '0.404' '0.405' '0.406'\n",
      " '0.407' '0.408' '0.409' '0.410' '0.411' '0.412' '0.413' '0.414' '0.415'\n",
      " '0.416' '0.417' '0.418' '0.419' '0.420' '0.421' '0.422' '0.423' '0.424'\n",
      " '0.425' '0.426' '0.427' '0.428' '0.429' '0.430' '0.431' '0.432' '0.433'\n",
      " '0.434' '0.435' '0.436' '0.437' '0.438' '0.439' '0.440' '0.441' '0.442'\n",
      " '0.443' '0.444' '0.445' '0.446' '0.447' '0.448' '0.449' '0.450' '0.451'\n",
      " '0.452' '0.453' '0.454' '0.455' '0.456' '0.457' '0.458' '0.459' '0.460'\n",
      " '0.461' '0.462' '0.463' '0.464' '0.465' '0.466' '0.467' '0.468' '0.469'\n",
      " '0.470' '0.471' '0.472' '0.473' '0.474' '0.475' '0.476' '0.477' '0.478'\n",
      " '0.479' '0.480' '0.481' '0.482' '0.483' '0.484' '0.485' '0.486' '0.487'\n",
      " '0.488' '0.489' '0.490' '0.491' '0.492' '0.493' '0.494' '0.495' '0.496'\n",
      " '0.497' '0.498' '0.499' '0.500' '0.501' '0.502' '0.503' '0.504' '0.505'\n",
      " '0.506' '0.507' '0.508' '0.509' '0.510' '0.511' '0.512' '0.513' '0.514'\n",
      " '0.515' '0.516' '0.517' '0.518' '0.519' '0.520' '0.521' '0.522' '0.523'\n",
      " '0.524' '0.525' '0.526' '0.527' '0.528' '0.529' '0.530' '0.531' '0.532'\n",
      " '0.533' '0.534' '0.535' '0.536' '0.537' '0.538' '0.539' '0.540' '0.541'\n",
      " '0.542' '0.543' '0.544' '0.545' '0.546' '0.547' '0.548' '0.549' '0.550'\n",
      " '0.551' '0.552' '0.553' '0.554' '0.555' '0.556' '0.557' '0.558' '0.559'\n",
      " '0.560' '0.561' '0.562' '0.563' '0.564' '0.565' '0.566' '0.567' '0.568'\n",
      " '0.569' '0.570' '0.571' '0.572' '0.573' '0.574' '0.575' '0.576' '0.577'\n",
      " '0.578' '0.579' '0.580' '0.581' '0.582' '0.583' '0.584' '0.585' '0.586'\n",
      " '0.587' '0.588' '0.589' '0.590' '0.591' '0.592' '0.593' '0.594' '0.595'\n",
      " '0.596' '0.597' '0.598' '0.599' '0.600' '0.601' '0.602' '0.603' '0.604'\n",
      " '1.2' '0.605' '0.606' '0.607' '0.608' '0.609' '0.610' '0.611' '0.612'\n",
      " '0.613' '0.614' '0.615' '0.616' '0.617' '0.618' '0.619' '0.620' '0.621'\n",
      " '0.622' '0.623' '0.624' '0.625' '0.626' '0.627' '0.628' '0.629' '0.630'\n",
      " '0.631' '0.632' '0.633' '0.634' '0.635' '0.636' '0.637' '0.638' '0.639'\n",
      " '0.640' '0.641' '0.642' '0.643' '0.644' '0.645' '0.646' '0.647' '0.648'\n",
      " '0.649' '0.650' '0.651' '0.652' '0.653' '0.654' '0.655' '0.656' '0.657'\n",
      " '0.658' '0.659' '0.660' '0.661' '0.662' '0.663' '0.664' '0.665' '0.666'\n",
      " '0.667' '0.668' '0.669' '0.670' '0.671' '0.672' '0.673' '0.674' '0.675'\n",
      " '0.676' '0.677' '0.678' '0.679' '0.680' '0.681' '0.682' '0.683' '0.684'\n",
      " '0.685' '0.686' '0.687' '0.688' '0.689' '0.690' '0.691' '0.692' '0.693'\n",
      " '0.694' '0.695' '0.696' '0.697' '0.698' '0.699' '0.700' '0.701' '0.702'\n",
      " '0.703' '0.704' '0.705' '0.706' '0.707' '0.708' '0.709' '0.710' '0.711'\n",
      " '0.712' '0.713' '0.714' '0.715' '0.716' '0.717' '0.718' '0.719' '0.720'\n",
      " '0.721' '0.722' '0.723' '0.724' '0.725' '0.726' '0.727' '0.728' '0.729'\n",
      " '0.730' '0.731' '0.732' '0.733' '0.734' '0.735' '0.736' '0.737' '0.738'\n",
      " '0.739' '0.740' '0.741' '0.742' '0.743' '0.744' '0.745' '0.746' '0.747'\n",
      " '0.748' '0.749' '0.750' '0.751' '0.752' '0.753' '0.754' '0.755' '0.756'\n",
      " '0.757' '0.758' '0.759' '0.760' '0.761' '0.762' '0.763' '0.764' '0.765'\n",
      " '0.766' '0.767' '0.768' '0.769' '0.770' '0.771' '0.772' '0.773' '0.774'\n",
      " '0.775' '0.776' '0.777' '0.778' '0.779' '0.780' '0.781' '0.782' '0.783'\n",
      " '0.784' '0.785' '0.786' '0.787' '0.788' '0.789' '0.790' '0.791' '0.792'\n",
      " '0.793' '0.794' '0.795' '0.796' '0.797' '0.798' '0.799' '0.800' '0.801'\n",
      " '0.802' '0.803' '0.804' '0.805' '0.806' '0.807' '0.808' '0.809' '0.810'\n",
      " '0.811' '0.812' '0.813' '0.814' '0.815' '0.816' '0.817' '0.818' '0.819'\n",
      " '0.820' '0.821' '0.822' '0.823' '0.824' '0.825' '0.826' '1.3' '0.827'\n",
      " '0.828' '0.829' '0.830' '0.831' '0.832' '0.833' '0.834' '0.835' '0.836'\n",
      " '0.837' '0.838' '0.839' '0.840' '0.841' '0.842' '0.843' '0.844' '0.845'\n",
      " '0.846' '0.847' '0.848' '0.849' '0.850' '0.851' '0.852']\n",
      "(856,)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "features_names = cnae_df.columns.values[1:] #Features names are the frequencies, of each world. There are 856 frequencies\n",
    "print (features_names)\n",
    "print (features_names.shape)\n",
    "print (features_names.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "guVrOCcALJK3",
    "outputId": "52d1d0de-c85f-4370-9172-4cf4b59167f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(1079, 856)\n",
      "2\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "features = cnae_df.values[:, cnae_df.columns != '1']\n",
    "print(features)\n",
    "# οι διαστάσεις όλων των χαρακτηριστικών\n",
    "# τα χαρακτηριστικά του πρώτου δείγματος\n",
    "print (features.shape)\n",
    "print (features.ndim)\n",
    "print (features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pxzx3dESbLF2"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split our data\n",
    "train, test, train_labels, test_labels = train_test_split(features, labels, test_size=0.30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ab5zsIDRf7qH"
   },
   "source": [
    "# Data Processing\n",
    "\n",
    "We see that we have too many features compared to our samples. So we will try to **make feature_selection**(i.e. VarianceThreshold), to see if we can get better results. Ειδικά στην περίπτωση που η διακύμανση είναι 0, δηλαδή το χαρακτηριστικό εχει σταθερή τιμή για όλα τα δείγματα εκπαίδευσης, δεν χρησιμέυει καθόλου στον ταξινομητή για να αποφασίσει αν ένα δείγμα ανήκει σε μία κλάση ή σε μια άλλη και επιπλέον μπορεί να δυσκολέψει άλλες διαδικασίες της προεπεξεργασίας όπως η κανανικοποίηση των χαρακτηριστικών.\n",
    "\n",
    "Επιπλέον, θα δοκιμάσουμε να κάνουμε εξαγωγή νέων χαρακτηριστικών σε ένα χώρο μικρότερων διαστάσεων (**feature extraction**). Η βασικότερη τεχνική feature extraction είναι η **ανάλυση σε κύριες συνιστώσες (principal components analysis - PCA)** όπου αναλύουμε τα δεδομένα σε κύριες συνιστώσες και δουλέυουμε με τελείως νέες, γραμμικά ασυσχέτιστες μεταβλητές μικρότερης διαστατικότητας. \n",
    "\n",
    "We have binary values in each class, οπότε δεν χρειάζεται να κανονικοποιήσουμε τα δεδομένα (**no scaling needed.** )\n",
    "\n",
    "Our Data are equally distributed to the classes, so there is **no need for balancing.** (over_sampling etc)\n",
    "\n",
    "Moreover, **since our data are equally distributed, there will be almost no difference in f1_micro and f1_macro metrics**. So, we will use f1_micro for choosing the best classifier in each case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lm9D8CsN6XX-"
   },
   "source": [
    "## Variance Thresholds\n",
    "We check some Variance Thresholds to see, between which ones should we choose later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Or39yxWz6Ref",
    "outputId": "190155ce-eb92-4887-8c6f-13b5da3e32f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(755, 856)\n",
      "(755, 729)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# αρχικοποιούμε έναν selector\n",
    "selector = VarianceThreshold(0)\n",
    "# όπως κάναμε και με τους ταξινομητές τον κάνουμε fit στα δεδομένα εκπαίδευσης\n",
    "train_reduced = selector.fit_transform(train)\n",
    "print(train.shape)\n",
    "print(train_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "o52dXDvM6ewM",
    "outputId": "27fd5e31-8c31-4c78-a33b-44b20233efe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(755, 856)\n",
      "(755, 29)\n"
     ]
    }
   ],
   "source": [
    "  # αρχικοποιούμε έναν selector\n",
    "selector = VarianceThreshold(0.05)\n",
    "# όπως κάναμε και με τους ταξινομητές τον κάνουμε fit στα δεδομένα εκπαίδευσης\n",
    "train_reduced = selector.fit_transform(train)\n",
    "print(train.shape)\n",
    "print(train_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "teZn9K3L6Tra",
    "outputId": "acf26ab7-d377-4953-acb4-3c1ec025711f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(755, 856)\n",
      "(755, 11)\n"
     ]
    }
   ],
   "source": [
    "# αρχικοποιούμε έναν selector\n",
    "selector = VarianceThreshold(0.1)\n",
    "# όπως κάναμε και με τους ταξινομητές τον κάνουμε fit στα δεδομένα εκπαίδευσης\n",
    "train_reduced = selector.fit_transform(train)\n",
    "print(train.shape)\n",
    "print(train_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NnHQZLvp5USb"
   },
   "source": [
    "It's clear that we should definetly choose a value below 0.05 because the features are reduced a lot and we will probably have a significant loss of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DFQoYtoh3ZZk"
   },
   "outputs": [],
   "source": [
    "# We will use the below dictionaries to compare the results of each classifier\n",
    "f1_macro_default={}\n",
    "f1_macro_optimized={}\n",
    "\n",
    "f1_micro_default={}\n",
    "f1_micro_optimized={}\n",
    "\n",
    "train_time_default={}\n",
    "train_time_optimized={}\n",
    "\n",
    "predict_time_default={}\n",
    "predict_time_optimized={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuE09FhLddqw"
   },
   "source": [
    "#Dummy Classifier\n",
    "\n",
    "Θα δοκιμάσουμε πρώτα να ταξινομήσουμε με τον DummyClassifier, ο οποίος δέχεται μια παράμετρο που καθορίζει την τακτική της ταξινόμησης ως εξής:\n",
    "* “uniform”: προβλέπει τυχαία και ομοιόμορφα.\n",
    "* “most_frequent”: προβλέπει πάντα την πιο συχνή κατηγορία στο training set.\n",
    "* “stratified”: κάνει προβλέψεις διατηρώντας την κατανομή των κλάσεων στο training set.\n",
    "\n",
    "Υπάρχει και η επιλογή  “constant” που προβλέπει πάντα μία κατηγορία που τη διαλέγει ο χρήστης. Παρόλα αυτά εδώ έχουμε 9 κατηγορίες, οπότε δεν θα τη μελετήσουμε εξαντλητικά."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "tAjOXRDPb6I2",
    "outputId": "99e60062-3072-4609-ee44-1ff042e8d709"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.17      0.12      0.14        48\n",
      "           2       0.03      0.03      0.03        30\n",
      "           3       0.18      0.19      0.19        36\n",
      "           4       0.12      0.11      0.11        37\n",
      "           5       0.12      0.13      0.13        38\n",
      "           6       0.21      0.25      0.23        32\n",
      "           7       0.13      0.17      0.15        29\n",
      "           8       0.12      0.11      0.11        47\n",
      "           9       0.00      0.00      0.00        27\n",
      "\n",
      "   micro avg       0.13      0.13      0.13       324\n",
      "   macro avg       0.12      0.12      0.12       324\n",
      "weighted avg       0.13      0.13      0.13       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "dc_uniform = DummyClassifier(strategy=\"uniform\")\n",
    "model = dc_uniform.fit(train, train_labels)\n",
    "preds = dc_uniform.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "ACc5X_GXijyl",
    "outputId": "44d1d0d9-5d66-4748-8a11-698e3c75fed8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.15      1.00      0.26        48\n",
      "           2       0.00      0.00      0.00        30\n",
      "           3       0.00      0.00      0.00        36\n",
      "           4       0.00      0.00      0.00        37\n",
      "           5       0.00      0.00      0.00        38\n",
      "           6       0.00      0.00      0.00        32\n",
      "           7       0.00      0.00      0.00        29\n",
      "           8       0.00      0.00      0.00        47\n",
      "           9       0.00      0.00      0.00        27\n",
      "\n",
      "   micro avg       0.15      0.15      0.15       324\n",
      "   macro avg       0.02      0.11      0.03       324\n",
      "weighted avg       0.02      0.15      0.04       324\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "dc_constant_1 = DummyClassifier(strategy=\"constant\", constant=1)\n",
    "model = dc_constant_1.fit(train, train_labels)\n",
    "preds = dc_constant_1.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "RSih6CY6ilBp",
    "outputId": "c4fbc1c5-fe05-4691-f283-0566e30468e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        48\n",
      "           2       0.00      0.00      0.00        30\n",
      "           3       0.00      0.00      0.00        36\n",
      "           4       0.00      0.00      0.00        37\n",
      "           5       0.00      0.00      0.00        38\n",
      "           6       0.00      0.00      0.00        32\n",
      "           7       0.00      0.00      0.00        29\n",
      "           8       0.00      0.00      0.00        47\n",
      "           9       0.08      1.00      0.15        27\n",
      "\n",
      "   micro avg       0.08      0.08      0.08       324\n",
      "   macro avg       0.01      0.11      0.02       324\n",
      "weighted avg       0.01      0.08      0.01       324\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "dc_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
    "model = dc_most_frequent.fit(train, train_labels)\n",
    "preds = dc_most_frequent.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "V1LypDrGimnS",
    "outputId": "6b14a225-ad0f-462d-b8d9-bf7be5ffde0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.07      0.04      0.05        48\n",
      "           2       0.03      0.03      0.03        30\n",
      "           3       0.13      0.14      0.14        36\n",
      "           4       0.30      0.27      0.29        37\n",
      "           5       0.07      0.08      0.07        38\n",
      "           6       0.14      0.16      0.15        32\n",
      "           7       0.05      0.07      0.06        29\n",
      "           8       0.08      0.04      0.05        47\n",
      "           9       0.06      0.11      0.08        27\n",
      "\n",
      "   micro avg       0.10      0.10      0.10       324\n",
      "   macro avg       0.10      0.10      0.10       324\n",
      "weighted avg       0.10      0.10      0.10       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dc_stratified = DummyClassifier(strategy=\"stratified\")\n",
    "\n",
    "start_time = time.time()\n",
    "model = dc_stratified.fit(train, train_labels)\n",
    "train_time = (time.time() - start_time)\n",
    "\n",
    "train_time_default['Dummy'] = train_time\n",
    "train_time_optimized['Dummy'] = train_time\n",
    "\n",
    "start_time = time.time()\n",
    "preds = dc_stratified.predict(test)\n",
    "pred_time = (time.time() - start_time)\n",
    "\n",
    "predict_time_default['Dummy'] = train_time\n",
    "predict_time_optimized['Dummy'] = train_time\n",
    "\n",
    "\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "P6xLu-S3Cs9W",
    "outputId": "aa56f6ea-b8cc-41d3-c40f-01c9ad84cce3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dummy': 0.002794981002807617}\n",
      "{'Dummy': 0.002794981002807617}\n"
     ]
    }
   ],
   "source": [
    "print(train_time_default)\n",
    "print(predict_time_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Yf_ObLBe3k7y",
    "outputId": "7e8e45e4-6437-4572-aa12-f334f68a5247"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dummy': 0.10209728647571724}\n",
      "{'Dummy': 0.10185185185185185}\n"
     ]
    }
   ],
   "source": [
    "#There is no point of optimizing the dummy classifier, so we will take as optimized the default value again\n",
    "report_dict = classification_report(test_labels, preds, output_dict = True)\n",
    "f1_macro_default['Dummy'] = report_dict['macro avg']['f1-score']\n",
    "f1_macro_optimized['Dummy'] = report_dict['macro avg']['f1-score']\n",
    "\n",
    "f1_micro_default['Dummy'] = report_dict['micro avg']['f1-score']\n",
    "f1_micro_optimized['Dummy'] = report_dict['micro avg']['f1-score']\n",
    "\n",
    "print(f1_macro_default)\n",
    "print(f1_micro_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xfa05xurnbnD"
   },
   "source": [
    "## Results\n",
    "We can see, that with the DummyClassifier, we can't achieve good results. So, we will move on and try the Naive Bayes Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rVf_cCc4oMWb"
   },
   "source": [
    "# Naive Bayes Classifier\n",
    "At Gaussian Naive Bayes Classifier, we asume that we have a Gaussian distribution with the $μ$ και $σ^2$ parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CniQTb_zhNsW"
   },
   "source": [
    "## Default without Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "-koMWfl7oWXO",
    "outputId": "7f68aa3f-6141-4ed6-c492-b9f840fb7c49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.92      0.95        48\n",
      "           2       1.00      0.97      0.98        30\n",
      "           3       0.68      0.89      0.77        36\n",
      "           4       0.77      0.54      0.63        37\n",
      "           5       0.95      1.00      0.97        38\n",
      "           6       0.96      0.84      0.90        32\n",
      "           7       0.79      0.93      0.86        29\n",
      "           8       0.94      1.00      0.97        47\n",
      "           9       0.88      0.81      0.85        27\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       324\n",
      "   macro avg       0.88      0.88      0.88       324\n",
      "weighted avg       0.89      0.88      0.88       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "# κάνουμε εκπαίδευση (fit) δηλαδή ουσιαστικά υπολογίζουμε μέση τιμή και διακύμανση για όλα τα χαρακτηριστικά και κλάσεις στο training set\n",
    "start_time = time.time()\n",
    "model = gnb.fit(train, train_labels)\n",
    "train_time = (time.time() - start_time)\n",
    "\n",
    "train_time_default['GaussianNB'] = train_time\n",
    "\n",
    "start_time = time.time()\n",
    "preds = gnb.predict(test)\n",
    "train_time = (time.time() - start_time)\n",
    "\n",
    "predict_time_default['GaussianNB'] = train_time\n",
    "\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6j0wYQM1DlJr",
    "outputId": "4a7adbb6-dc22-4dcd-ab2a-74b66dd74272"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dummy': 0.002794981002807617, 'GaussianNB': 0.027896642684936523}\n",
      "{'Dummy': 0.002794981002807617, 'GaussianNB': 0.02132248878479004}\n"
     ]
    }
   ],
   "source": [
    "print(train_time_default)\n",
    "print(predict_time_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0QiIoLPziyG0",
    "outputId": "c5324d7b-938d-4690-a5f7-6aa8885511d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dummy': 0.10209728647571724, 'GaussianNB': 0.8757800246079528}\n",
      "{'Dummy': 0.10185185185185185, 'GaussianNB': 0.8827160493827161}\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(test_labels, preds, output_dict = True)\n",
    "f1_macro_default['GaussianNB'] = report_dict['macro avg']['f1-score']\n",
    "f1_micro_default['GaussianNB'] = report_dict['micro avg']['f1-score']\n",
    "\n",
    "print(f1_macro_default)\n",
    "print(f1_micro_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7CWq6BBCoyxl"
   },
   "source": [
    "## Results\n",
    "Here we can see, that we have much greater reults, reaching a quite good f1-score. However, we want to see if we can do better with the kNN classifier. Moreover, we see as expected that the f1-macro and f1-micro scores are quite similar, beacause our classes are equally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mTpBC8OT3M51"
   },
   "source": [
    "##Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DOZjwoOF1P4s"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade imbalanced-learn\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# φέρνουμε τις γνωστές μας κλάσεις για preprocessing\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kzzdn8_V1UXI"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "clf = GaussianNB()\n",
    "\n",
    "vthreshold = [0, 0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4hXMGm-i1p6T"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector), ('gaussiannb', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-pZZG7H2SM0"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold), cv=5, scoring='f1_micro', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "phpoGtc52cU1",
    "outputId": "eae8222f-3cb1-4620-b25d-a5d375a8318a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 0.04953156709671021 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.92      0.95        48\n",
      "           2       1.00      0.97      0.98        30\n",
      "           3       0.68      0.89      0.77        36\n",
      "           4       0.77      0.54      0.63        37\n",
      "           5       0.95      1.00      0.97        38\n",
      "           6       0.96      0.84      0.90        32\n",
      "           7       0.79      0.93      0.86        29\n",
      "           8       0.94      1.00      0.97        47\n",
      "           9       0.88      0.81      0.85        27\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       324\n",
      "   macro avg       0.88      0.88      0.88       324\n",
      "weighted avg       0.89      0.88      0.88       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "total_time = (time.time() - start_time)/60\n",
    "print(\"Fit done in:\",total_time,\"minutes\")\n",
    "preds = estimator.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "wCLcB7eD2qvb",
    "outputId": "54b093e0-9a21-4032-95eb-1d8930ed4897"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='tmp',\n",
      "     steps=[('selector', VarianceThreshold(threshold=0)), ('gaussiannb', GaussianNB(priors=None, var_smoothing=1e-09))])\n",
      "{'selector__threshold': 0}\n"
     ]
    }
   ],
   "source": [
    "print (estimator.best_estimator_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yeGR06Nj6JxB"
   },
   "source": [
    "###Progressive Threshold\n",
    "We see that we get the best results, for the Variance Threshold 0. However, we still have a lot of Features compared to the Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "FA0xS5ba6JHa",
    "outputId": "fd79df1f-1f16-4dbe-a29d-41bbe3eb631e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(755, 856)\n",
      "(755, 729)\n"
     ]
    }
   ],
   "source": [
    "# αρχικοποιούμε έναν selector\n",
    "selector = VarianceThreshold(0)\n",
    "# όπως κάναμε και με τους ταξινομητές τον κάνουμε fit στα δεδομένα εκπαίδευσης\n",
    "train_reduced = selector.fit_transform(train)\n",
    "print(train.shape)\n",
    "print(train_reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0oJvXMHQSDo"
   },
   "source": [
    "So, we will try to set a higher thershold to see if we can achieve better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FWgjrD4WQRbX"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "clf = GaussianNB()\n",
    "\n",
    "vthreshold = [0, 0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LWk2m1fARqge"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector), ('gaussiannb', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owhF5rZBRvbL"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold), cv=5, scoring='f1_micro', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "ex6EPh-AR6Qr",
    "outputId": "5a2da478-2382-44ec-9392-904eaaea26f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 0.03586727778116862 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.92      0.95        48\n",
      "           2       1.00      0.97      0.98        30\n",
      "           3       0.68      0.89      0.77        36\n",
      "           4       0.77      0.54      0.63        37\n",
      "           5       0.95      1.00      0.97        38\n",
      "           6       0.96      0.84      0.90        32\n",
      "           7       0.79      0.93      0.86        29\n",
      "           8       0.94      1.00      0.97        47\n",
      "           9       0.88      0.81      0.85        27\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       324\n",
      "   macro avg       0.88      0.88      0.88       324\n",
      "weighted avg       0.89      0.88      0.88       324\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "total_time = (time.time() - start_time)/60\n",
    "print(\"Fit done in:\",total_time,\"minutes\")\n",
    "preds = estimator.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "yEQASDwRR94m",
    "outputId": "347c9b54-dc67-4d99-e21b-a8af724473ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='tmp',\n",
      "     steps=[('selector', VarianceThreshold(threshold=0)), ('gaussiannb', GaussianNB(priors=None, var_smoothing=1e-09))])\n",
      "{'selector__threshold': 0}\n"
     ]
    }
   ],
   "source": [
    "print (estimator.best_estimator_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vrKOsa4x7K9q"
   },
   "source": [
    "We will try to optimize it with PCA, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VwjjDv9_5b1w"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "pca = PCA()\n",
    "clf = GaussianNB()\n",
    "\n",
    "vthreshold = [0]\n",
    "n_components = [69,70,72,73,74,75,80]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D8vDOili7fuf"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector),('pca',pca), ('gaussiannb', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vZyBn-0U7shm"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, pca__n_components=n_components), cv=5, scoring='f1_micro', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "T44vXTJx70cB",
    "outputId": "d9063497-f81d-4349-d619-f07e11fbbb35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 0.11727774540583293 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.88      0.88        48\n",
      "           2       1.00      0.80      0.89        30\n",
      "           3       0.97      0.86      0.91        36\n",
      "           4       0.76      0.70      0.73        37\n",
      "           5       0.88      1.00      0.94        38\n",
      "           6       0.64      0.84      0.73        32\n",
      "           7       0.89      0.86      0.88        29\n",
      "           8       0.82      0.89      0.86        47\n",
      "           9       0.78      0.67      0.72        27\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       324\n",
      "   macro avg       0.85      0.83      0.84       324\n",
      "weighted avg       0.85      0.84      0.84       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "total_time = (time.time() - start_time)/60\n",
    "print(\"Fit done in:\",total_time,\"minutes\")\n",
    "preds = estimator.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "UOVmcgAY728y",
    "outputId": "98f7ceaf-c9c9-4fb7-d214-d89c97f79800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='tmp',\n",
      "     steps=[('selector', VarianceThreshold(threshold=0)), ('pca', PCA(copy=True, iterated_power='auto', n_components=73, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('gaussiannb', GaussianNB(priors=None, var_smoothing=1e-09))])\n",
      "{'pca__n_components': 73, 'selector__threshold': 0}\n"
     ]
    }
   ],
   "source": [
    "print (estimator.best_estimator_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmom6SsR8gbR"
   },
   "source": [
    "##Results\n",
    "\n",
    "We can see here, that although we have less dimensions, we get lower results, when we try to optimize with PCA . This means, that reducing the dimensions using PCA, causes sgnificant loss of information. So, our best score here, is by only using as Variance Threshold 0. \n",
    "\n",
    "It is also important to note that the PCA values used here, were choosen after more experiments in greater values. For example, we tried to keep 300 or 200 dimensions but the best results using PCA was around 70 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LJYZemo8S-KH"
   },
   "source": [
    "##Final GaussianNB Classifier\n",
    "We will finally run the classifier one ore time with the best parameters in order to get the training and the predict times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i-vsjEKPTW3k"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "clf = GaussianNB()\n",
    "\n",
    "vthreshold = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N4ik69SpTYOo"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector), ('gaussiannb', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JTs99e7LTiey"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold), cv=5, scoring='f1_micro', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "zcwFmTxlTygm",
    "outputId": "22122466-157f-4081-ce08-cff222a42d88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 0.30923914909362793 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.92      0.95        48\n",
      "           2       1.00      0.97      0.98        30\n",
      "           3       0.68      0.89      0.77        36\n",
      "           4       0.77      0.54      0.63        37\n",
      "           5       0.95      1.00      0.97        38\n",
      "           6       0.96      0.84      0.90        32\n",
      "           7       0.79      0.93      0.86        29\n",
      "           8       0.94      1.00      0.97        47\n",
      "           9       0.88      0.81      0.85        27\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       324\n",
      "   macro avg       0.88      0.88      0.88       324\n",
      "weighted avg       0.89      0.88      0.88       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "total_time = (time.time() - start_time)\n",
    "\n",
    "train_time_optimized['GaussianNB'] = total_time\n",
    "print(\"Fit done in:\",total_time,\"seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "preds = estimator.predict(test)\n",
    "total_time = (time.time() - start_time)\n",
    "\n",
    "predict_time_optimized['GaussianNB'] = total_time\n",
    "\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "MjPkcjsQUMpg",
    "outputId": "699cb240-3c1b-4e04-b849-6f1f40531ea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dummy': 0.10209728647571724, 'GaussianNB': 0.8757800246079528}\n",
      "{'Dummy': 0.10209728647571724, 'GaussianNB': 0.8757800246079528}\n",
      "{'Dummy': 0.10185185185185185, 'GaussianNB': 0.8827160493827161}\n",
      "{'Dummy': 0.10185185185185185, 'GaussianNB': 0.8827160493827161}\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(test_labels, preds, output_dict = True)\n",
    "f1_macro_optimized['GaussianNB'] = report_dict['macro avg']['f1-score']\n",
    "f1_micro_optimized['GaussianNB'] = report_dict['micro avg']['f1-score']\n",
    "\n",
    "print(f1_macro_default)\n",
    "print(f1_macro_optimized)\n",
    "print(f1_micro_default)\n",
    "print(f1_micro_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "NqMcH3FtVaDu",
    "outputId": "79f3f9f6-3cad-4f45-dfab-10cd9a6eaf9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dummy': 0.002794981002807617, 'GaussianNB': 0.027896642684936523}\n",
      "{'Dummy': 0.002794981002807617, 'GaussianNB': 0.02132248878479004}\n",
      "{'Dummy': 0.002794981002807617, 'GaussianNB': 0.30923914909362793}\n",
      "{'Dummy': 0.002794981002807617, 'GaussianNB': 0.015270471572875977}\n"
     ]
    }
   ],
   "source": [
    "print(train_time_default)\n",
    "print(predict_time_default)\n",
    "print(train_time_optimized)\n",
    "print(predict_time_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gdnqvlsPU2K0"
   },
   "source": [
    "So it is clear that the Variance Threshold doesn't affect the GaussianNB Classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z6IV2GTKpODS"
   },
   "source": [
    "#kNN Classifier\n",
    "In order to find the best k-parameter for our exercise, we would like to train the model and compare the results of k=1 to k=n , where n has a big value. If we do that, we will use multiple times our testing data to see which value for the k parameter would be better. However, in this way, we will have overfitting of our model making it too specific in our testing data. So, in order to avoid this problem, we will use 5-fold vallidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pX4AF0UKhaYJ"
   },
   "source": [
    "##Default without Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "wh4RHsX1qYnn",
    "outputId": "4fd676e6-cb63-4108-a6b0-ffe9b6133e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 0.01602029800415039 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.85      0.96      0.90        48\n",
      "           2       0.87      0.90      0.89        30\n",
      "           3       0.84      0.75      0.79        36\n",
      "           4       0.82      0.62      0.71        37\n",
      "           5       1.00      1.00      1.00        38\n",
      "           6       0.81      0.69      0.75        32\n",
      "           7       0.62      0.97      0.76        29\n",
      "           8       0.96      0.94      0.95        47\n",
      "           9       0.70      0.59      0.64        27\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       324\n",
      "   macro avg       0.83      0.82      0.82       324\n",
      "weighted avg       0.84      0.84      0.83       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# kNN with Default values\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "knn.fit(train, train_labels)\n",
    "total_time = (time.time() - start_time)\n",
    "\n",
    "train_time_default['kNN'] = total_time\n",
    "print(\"Fit done in:\",total_time,\"seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "preds = knn.predict(test)\n",
    "total_time = (time.time() - start_time)\n",
    "\n",
    "predict_time_default['kNN'] = total_time\n",
    "\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ICUzFl0KXr0Y",
    "outputId": "60947c3b-a8c4-4437-a5c5-6de2b7d9fb4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dummy': 0.10209728647571724, 'GaussianNB': 0.8757800246079528, 'kNN': 0.8197525187183499}\n",
      "{'Dummy': 0.10185185185185185, 'GaussianNB': 0.8827160493827161, 'kNN': 0.8364197530864198}\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(test_labels, preds, output_dict = True)\n",
    "f1_macro_default['kNN'] = report_dict['macro avg']['f1-score']\n",
    "f1_micro_default['kNN'] = report_dict['micro avg']['f1-score']\n",
    "\n",
    "print(f1_macro_default)\n",
    "print(f1_micro_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iTfwU00j_mxj"
   },
   "source": [
    "##Data Processing and Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vD-FdDM2_sR3"
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade imbalanced-learn\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# φέρνουμε τις γνωστές μας κλάσεις για preprocessing\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3jzjCq_fnYsi"
   },
   "source": [
    "Στη συνέχεια θα χρησιμποιήσουμε την GridSearchCV για να βελτιστοποιήσουμε τις υπερπαραμέτρους μας. Η GridSearchCV κάνει μαζί cross-validation και grid search. Την εισάγουμε και θέτουμε το πεδίο τιμών:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ad_H7QR9nmJ0"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "#pca = PCA()\n",
    "clf = KNeighborsClassifier(n_jobs=-1) # η παράμετρος n_jobs = -1 χρησιμοποιεί όλους τους πυρήνες του υπολογιστή\n",
    "\n",
    "vthreshold = [0, 0.001, 0.002, 0.005, 0.01]\n",
    "#n_components = [10, 20, 25, 30]\n",
    "k = [1, 3, 5, 7, 10, 15, 20]\n",
    "## 'uniform': All points in each neighborhood are weighted equally\n",
    "## 'distance': Closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "weights_options = ['uniform', 'distance']\n",
    "metric_options = ['euclidean', 'manhattan', 'chebyshev', 'minkowski', 'hamming'] #default minkowski\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8a16zb2CriyA"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector), ('kNN', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGJ5NtqaDa1Z"
   },
   "source": [
    "We will use n_jobs=-1 so that all the cores of our machine will be used and verbose=10, for checking how the training is progressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aKpyWcHln2dw"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, kNN__n_neighbors=k, kNN__weights=weights_options, kNN__metric=metric_options), cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2TOVb69DsLRD"
   },
   "source": [
    "Το GridSearchCV είναι επίσης ένας estimator με fit και predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1380
    },
    "colab_type": "code",
    "id": "FP-L7SlfsK9H",
    "outputId": "f2d9d5d8-8310-44de-8930-3a9b11b63f13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 350 candidates, totalling 1750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:   23.1s\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:   28.0s\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:   38.2s\n",
      "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:   43.7s\n",
      "[Parallel(n_jobs=-1)]: Done 177 tasks      | elapsed:   48.6s\n",
      "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:   54.9s\n",
      "[Parallel(n_jobs=-1)]: Done 217 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 238 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 261 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 284 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 309 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 334 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 361 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 388 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 417 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 477 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 508 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 541 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 574 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 609 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 644 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 681 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 718 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 757 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done 837 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 878 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 921 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done 964 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1009 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1054 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1101 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1148 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1197 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1246 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1297 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1348 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1401 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1454 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1509 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1564 tasks      | elapsed:  7.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1621 tasks      | elapsed:  7.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1678 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1737 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1750 out of 1750 | elapsed:  8.0min finished\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 8.036914523442586 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.96      0.91        48\n",
      "           2       0.90      0.87      0.88        30\n",
      "           3       0.85      0.81      0.83        36\n",
      "           4       0.90      0.70      0.79        37\n",
      "           5       1.00      1.00      1.00        38\n",
      "           6       0.92      0.75      0.83        32\n",
      "           7       0.79      0.93      0.86        29\n",
      "           8       0.96      0.96      0.96        47\n",
      "           9       0.71      0.89      0.79        27\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       324\n",
      "   macro avg       0.88      0.87      0.87       324\n",
      "weighted avg       0.89      0.88      0.88       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "total_time = (time.time() - start_time)\n",
    "print(\"Fit done in:\",total_time/60,\"minutes\")\n",
    "preds = estimator.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Kba-qpcYsgm9",
    "outputId": "ac575d83-6b40-4bfe-d622-0a2ae5fa8d7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='tmp',\n",
      "     steps=[('selector', VarianceThreshold(threshold=0)), ('kNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=10, p=2,\n",
      "           weights='distance'))])\n",
      "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 10, 'kNN__weights': 'distance', 'selector__threshold': 0}\n"
     ]
    }
   ],
   "source": [
    "print (estimator.best_estimator_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2r0zpqdQMZQa"
   },
   "source": [
    "### Progressive grid search\n",
    "\n",
    "- Στο πεδίο ορισμού των παραμέτρων, ξεκινάμε με μεγάλα διαστήματα και σχετικά λίγα βήματα. Αν διαπιστώσουμε ότι υπαρχει μια περιοχή τιμών κάποιας παραμέτρου που δίνει καλη απόδοση μπορούμε να μικρύνουμε το διάστημα του grid search γύρω της και να βάλουμε περισσότερα βήματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6BzmGFRMCJ1"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "#pca = PCA()\n",
    "clf = KNeighborsClassifier(n_jobs=-1) # η παράμετρος n_jobs = -1 χρησιμοποιεί όλους τους πυρήνες του υπολογιστή\n",
    "\n",
    "vthreshold = [0]\n",
    "#n_components = [30, 50, 70, 100]\n",
    "k = [8,9,10,11,12]\n",
    "## 'uniform': All points in each neighborhood are weighted equally\n",
    "## 'distance': Closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "weights_options = ['distance']\n",
    "metric_options = ['euclidean'] #default minkowski\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nPVrr1QbMix8"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector), ('kNN', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0bBJx9S-Mqjb"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, kNN__n_neighbors=k,kNN__weights=weights_options, kNN__metric=metric_options), cv=5, scoring='f1_micro', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "Ir9cZNUuMuer",
    "outputId": "a5b90fe0-d1d1-4325-aba5-ec3efce78964"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 0.2207120895385742 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.96      0.91        48\n",
      "           2       0.90      0.87      0.88        30\n",
      "           3       0.85      0.81      0.83        36\n",
      "           4       0.90      0.70      0.79        37\n",
      "           5       1.00      1.00      1.00        38\n",
      "           6       0.92      0.75      0.83        32\n",
      "           7       0.79      0.93      0.86        29\n",
      "           8       0.96      0.96      0.96        47\n",
      "           9       0.71      0.89      0.79        27\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       324\n",
      "   macro avg       0.88      0.87      0.87       324\n",
      "weighted avg       0.89      0.88      0.88       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "total_time = (time.time() - start_time)\n",
    "print(\"Fit done in:\",total_time/60,\"minutes\")\n",
    "preds = estimator.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "w9JMqq3yMx9c",
    "outputId": "c9b4d234-6fc1-463f-c8e2-a904f4cc1199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='tmp',\n",
      "     steps=[('selector', VarianceThreshold(threshold=0)), ('kNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=10, p=2,\n",
      "           weights='distance'))])\n",
      "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 10, 'kNN__weights': 'distance', 'selector__threshold': 0}\n"
     ]
    }
   ],
   "source": [
    "print (estimator.best_estimator_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iADZgfd6NRsz"
   },
   "source": [
    "### We now check if PCA could improve our score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARZo7tsyNOFI"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "pca = PCA()\n",
    "clf = KNeighborsClassifier(n_jobs=-1) # η παράμετρος n_jobs = -1 χρησιμοποιεί όλους τους πυρήνες του υπολογιστή\n",
    "\n",
    "vthreshold = [0]\n",
    "n_components = [100, 200, 260, 265, 270, 275, 279]\n",
    "k = [10]\n",
    "## 'uniform': All points in each neighborhood are weighted equally\n",
    "## 'distance': Closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "weights_options = ['distance']\n",
    "metric_options = ['euclidean'] #default minkowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H4_BVgTiNmlK"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector),('pca',pca), ('kNN', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aF4uIO8NndY"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, kNN__n_neighbors=k, pca__n_components=n_components, kNN__weights=weights_options, kNN__metric=metric_options), cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "Sj_e6HT8Nt26",
    "outputId": "bc8661f1-d278-4673-bcc8-e6d6d5e431af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  35 | elapsed:    9.6s finished\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 0.17122799555460613 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.92      0.94        48\n",
      "           2       0.97      0.93      0.95        30\n",
      "           3       0.86      0.83      0.85        36\n",
      "           4       0.90      0.70      0.79        37\n",
      "           5       1.00      0.97      0.99        38\n",
      "           6       0.96      0.78      0.86        32\n",
      "           7       0.82      0.93      0.87        29\n",
      "           8       0.96      0.91      0.93        47\n",
      "           9       0.57      0.93      0.70        27\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       324\n",
      "   macro avg       0.89      0.88      0.88       324\n",
      "weighted avg       0.90      0.88      0.88       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "total_time = time.time() - start_time\n",
    "print(\"Fit done in:\",total_time/60,\"minutes\")\n",
    "preds = estimator.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "rnkAiHcHNwZF",
    "outputId": "6b49bd5d-f72f-4d94-f48a-6426e611a94f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='tmp',\n",
      "     steps=[('selector', VarianceThreshold(threshold=0)), ('pca', PCA(copy=True, iterated_power='auto', n_components=279, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('kNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=10, p=2,\n",
      "           weights='distance'))])\n",
      "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 10, 'kNN__weights': 'distance', 'pca__n_components': 279, 'selector__threshold': 0}\n"
     ]
    }
   ],
   "source": [
    "print (estimator.best_estimator_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "emm-MK12PHxj"
   },
   "source": [
    "### More Progressive 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KGEKtUAtPDgQ"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "pca = PCA()\n",
    "clf = KNeighborsClassifier(n_jobs=-1) # η παράμετρος n_jobs = -1 χρησιμοποιεί όλους τους πυρήνες του υπολογιστή\n",
    "\n",
    "vthreshold = [0]\n",
    "n_components = [450,460,470,480,490,500,520,550,570]\n",
    "k = [10]\n",
    "## 'uniform': All points in each neighborhood are weighted equally\n",
    "## 'distance': Closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "weights_options = ['distance']\n",
    "metric_options = ['euclidean'] #default minkowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AwsjtDfuPPFL"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector),('pca',pca), ('kNN', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_GT88elPRWq"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, kNN__n_neighbors=k, pca__n_components=n_components, kNN__weights=weights_options, kNN__metric=metric_options), cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "zAsKCwtYPT4N",
    "outputId": "8518162e-e34c-46ff-d6d7-02fcbc1a8702"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   33.4s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   40.1s finished\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 0.6864362041155497 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.92      0.93        48\n",
      "           2       0.71      0.90      0.79        30\n",
      "           3       0.87      0.72      0.79        36\n",
      "           4       0.86      0.65      0.74        37\n",
      "           5       1.00      0.97      0.99        38\n",
      "           6       1.00      0.81      0.90        32\n",
      "           7       0.80      0.97      0.88        29\n",
      "           8       0.92      0.96      0.94        47\n",
      "           9       0.65      0.81      0.72        27\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       324\n",
      "   macro avg       0.86      0.86      0.85       324\n",
      "weighted avg       0.87      0.86      0.86       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "print(\"Fit done in:\",(time.time() - start_time)/60,\"minutes\")\n",
    "preds = estimator.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "Si45ebY5PVzN",
    "outputId": "d093e544-fb89-4eb8-df64-43be5c3e05e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='tmp',\n",
      "     steps=[('selector', VarianceThreshold(threshold=0)), ('pca', PCA(copy=True, iterated_power='auto', n_components=490, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('kNN', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
      "           metric_params=None, n_jobs=-1, n_neighbors=10, p=2,\n",
      "           weights='distance'))])\n",
      "{'kNN__metric': 'euclidean', 'kNN__n_neighbors': 10, 'kNN__weights': 'distance', 'pca__n_components': 490, 'selector__threshold': 0}\n"
     ]
    }
   ],
   "source": [
    "print (estimator.best_estimator_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXVjuFSwcilD"
   },
   "source": [
    "###Results\n",
    "Here PCA helps us just a little more in increasing our score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Clb_4qwMc8Bv"
   },
   "source": [
    "##Final kNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xC4pegTudFsX"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "pca = PCA()\n",
    "clf = KNeighborsClassifier(n_jobs=-1) # η παράμετρος n_jobs = -1 χρησιμοποιεί όλους τους πυρήνες του υπολογιστή\n",
    "\n",
    "vthreshold = [0]\n",
    "n_components = [279]\n",
    "k = [10]\n",
    "## 'uniform': All points in each neighborhood are weighted equally\n",
    "## 'distance': Closer neighbors of a query point will have a greater influence than neighbors which are further away.\n",
    "weights_options = ['distance']\n",
    "metric_options = ['euclidean'] #default minkowski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZ3vc_9wdWg6"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector),('pca',pca),('kNN', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1HMxfz-Idc-f"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, kNN__n_neighbors=k,kNN__weights=weights_options, kNN__metric=metric_options, pca__n_components=n_components), cv=5, scoring='f1_micro', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "colab_type": "code",
    "id": "4vDsYUvKdhM9",
    "outputId": "848c58fd-4585-482d-f952-7e7e2c3c7add"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 0.024713317553202312 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.92      0.94        48\n",
      "           2       0.97      0.93      0.95        30\n",
      "           3       0.86      0.83      0.85        36\n",
      "           4       0.90      0.70      0.79        37\n",
      "           5       1.00      0.97      0.99        38\n",
      "           6       0.96      0.78      0.86        32\n",
      "           7       0.82      0.93      0.87        29\n",
      "           8       0.96      0.91      0.93        47\n",
      "           9       0.57      0.93      0.70        27\n",
      "\n",
      "   micro avg       0.88      0.88      0.88       324\n",
      "   macro avg       0.89      0.88      0.88       324\n",
      "weighted avg       0.90      0.88      0.88       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "total_time = (time.time() - start_time)\n",
    "\n",
    "train_time_optimized['kNN'] = total_time\n",
    "\n",
    "print(\"Fit done in:\",(time.time() - start_time)/60,\"minutes\")\n",
    "\n",
    "start_time = time.time()\n",
    "preds = estimator.predict(test)\n",
    "total_time = (time.time() - start_time)\n",
    "\n",
    "predict_time_optimized['kNN'] = total_time\n",
    "\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "HVOI7UxQeBEf",
    "outputId": "2067127c-6064-4198-a5f6-d755f28120c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dummy': 0.10209728647571724, 'GaussianNB': 0.8757800246079528, 'kNN': 0.8197525187183499}\n",
      "{'Dummy': 0.10209728647571724, 'GaussianNB': 0.8757800246079528, 'kNN': 0.875220366720062}\n",
      "{'Dummy': 0.10185185185185185, 'GaussianNB': 0.8827160493827161, 'kNN': 0.8364197530864198}\n",
      "{'Dummy': 0.10185185185185185, 'GaussianNB': 0.8827160493827161, 'kNN': 0.8796296296296297}\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(test_labels, preds, output_dict = True)\n",
    "f1_macro_optimized['kNN'] = report_dict['macro avg']['f1-score']\n",
    "f1_micro_optimized['kNN'] = report_dict['micro avg']['f1-score']\n",
    "\n",
    "print(f1_macro_default)\n",
    "print(f1_macro_optimized)\n",
    "print(f1_micro_default)\n",
    "print(f1_micro_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "tTMnDtKLeLEg",
    "outputId": "59d2a036-992b-41ba-e804-ec7b8f8b61bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dummy': 0.002794981002807617, 'GaussianNB': 0.027896642684936523, 'kNN': 0.01602029800415039}\n",
      "{'Dummy': 0.002794981002807617, 'GaussianNB': 0.02132248878479004, 'kNN': 0.4556434154510498}\n",
      "{'Dummy': 0.002794981002807617, 'GaussianNB': 0.30923914909362793, 'kNN': 1.4826996326446533}\n",
      "{'Dummy': 0.002794981002807617, 'GaussianNB': 0.015270471572875977, 'kNN': 0.21165895462036133}\n"
     ]
    }
   ],
   "source": [
    "print(train_time_default)\n",
    "print(predict_time_default)\n",
    "print(train_time_optimized)\n",
    "print(predict_time_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Db0pjvuaD0Zz"
   },
   "source": [
    "#MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V63M3-B-h3Z7"
   },
   "source": [
    "##Default without Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "rWOmCym_jdgo",
    "outputId": "756e0045-7360-47a8-f239-4c8773332fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 5.070923566818237 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.96      0.97        48\n",
      "           2       1.00      0.97      0.98        30\n",
      "           3       0.97      0.89      0.93        36\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       1.00      1.00      1.00        38\n",
      "           6       0.94      0.94      0.94        32\n",
      "           7       1.00      1.00      1.00        29\n",
      "           8       1.00      0.98      0.99        47\n",
      "           9       0.86      0.89      0.87        27\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       324\n",
      "   macro avg       0.95      0.95      0.95       324\n",
      "weighted avg       0.96      0.95      0.95       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#default parameters\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = MLPClassifier()\n",
    "\n",
    "start_time = time.time()\n",
    "clf.fit(train, train_labels)\n",
    "total_time = (time.time() - start_time)\n",
    "\n",
    "train_time_default['MLPClassifier'] = total_time\n",
    "print(\"Fit done in:\",total_time,\"seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "preds = clf.predict(test)\n",
    "total_time = (time.time() - start_time)\n",
    "\n",
    "predict_time_default['MLPClassifier'] = total_time\n",
    "\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "v3bDvyqQe0rR",
    "outputId": "ddf8f1f7-1dc9-41e7-a903-9094f2173eba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dummy': 0.10209728647571724, 'GaussianNB': 0.8757800246079528, 'kNN': 0.8197525187183499, 'MLPClassifier': 0.9516176295439536}\n",
      "{'Dummy': 0.10185185185185185, 'GaussianNB': 0.8827160493827161, 'kNN': 0.8364197530864198, 'MLPClassifier': 0.9537037037037037}\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(test_labels, preds, output_dict = True)\n",
    "f1_macro_default['MLPClassifier'] = report_dict['macro avg']['f1-score']\n",
    "f1_micro_default['MLPClassifier'] = report_dict['micro avg']['f1-score']\n",
    "\n",
    "print(f1_macro_default)\n",
    "print(f1_micro_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m30lEIEoYEbE"
   },
   "source": [
    "## Optimize MLPClassifier\n",
    "At first we will not use the Variance Thesfold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9jDqquTOSG3W"
   },
   "outputs": [],
   "source": [
    "## Parameters to optimize\n",
    "parameter_space = {\n",
    "  #'hidden_layer_sizes': [(5,) , (15,) , (20,) , (50,) , (100,)], # tuple default (100,).The ith element represents the number of neurons in the ith hidden layer.\n",
    "  'activation': ['identity', 'logistic', 'tanh', 'relu'], # default ‘relu’\n",
    "  'solver': ['lbfgs','sgd','adam'], # default ‘adam’\n",
    "  #'learning_rate': ['constant','invscaling','adaptive'] # Only used when solver='sgd'.\n",
    "  #'max_iter': [100,150,200,250],\n",
    "  #'alpha': [0.0001, 0.002, 0.05] \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MWAbJZGfpgR"
   },
   "source": [
    "Because the parameters to be optimized are too many and if we use them all in our GridSearch our Training will take too long, we will use at first only some combinations of them. Fow example, we know that the learning rate is used only when the solver is the sgd, so we will use it later in a next GridSearch. We also know that max_iter is mostly needed for the adam and lbfgs beacause they need more iterations to converge. \n",
    "\n",
    "We will first, try to see whch solver with which activation gives us the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XI9aF243b2lZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=5, scoring='f1_micro', verbose=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "colab_type": "code",
    "id": "GbjwHlalcIhq",
    "outputId": "212f3658-c98a-4b1d-9cbd-614932d7e5cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   24.8s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   59.1s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:  4.1min finished\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 4.166160221894582 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.96      0.97        48\n",
      "           2       1.00      0.97      0.98        30\n",
      "           3       0.97      0.86      0.91        36\n",
      "           4       0.81      0.95      0.88        37\n",
      "           5       1.00      1.00      1.00        38\n",
      "           6       0.94      0.94      0.94        32\n",
      "           7       1.00      1.00      1.00        29\n",
      "           8       1.00      0.98      0.99        47\n",
      "           9       0.86      0.89      0.87        27\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       324\n",
      "   macro avg       0.95      0.95      0.95       324\n",
      "weighted avg       0.95      0.95      0.95       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "clf.fit(train, train_labels)\n",
    "print(\"Fit done in:\",(time.time() - start_time)/60,\"minutes\")\n",
    "preds = clf.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OmlLjlLhcZUa",
    "outputId": "741219c6-56df-492c-80e4-bb4aa6abb6fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "#print (estimator.best_estimator_)\n",
    "print (clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uPBB1gx_m5ip"
   },
   "source": [
    "It's important to mention that the optimal parameters choosen were also the default ones. Since that didn 't take much time, we will check again if we can get any better results by using the Variance Theshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OL0bBarQnRgp"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "#pca = PCA()\n",
    "clf = MLPClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'selector__threshold': [0,0.001, 0.002],\n",
    "    'mlpclassifier__activation': ['relu'],\n",
    "    'mlpclassifier__solver': ['adam']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uOILxQ44nVXl"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "910r2TQ9olav"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "MxsIDncMpJb4",
    "outputId": "e855677b-8426-497e-a108-813ab713b39d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   50.7s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 1.2216644843419393 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.96      0.98        48\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       0.97      0.89      0.93        36\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       1.00      1.00      1.00        38\n",
      "           6       0.94      0.94      0.94        32\n",
      "           7       1.00      1.00      1.00        29\n",
      "           8       1.00      0.98      0.99        47\n",
      "           9       0.86      0.89      0.87        27\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       324\n",
      "   macro avg       0.96      0.96      0.95       324\n",
      "weighted avg       0.96      0.96      0.96       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "print(\"Fit done in:\",(time.time() - start_time)/60,\"minutes\")\n",
    "preds = estimator.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "apS8p6MdpTgv",
    "outputId": "8654a5fa-9628-4bca-9558-da0568e147fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='tmp',\n",
      "     steps=[('selector', VarianceThreshold(threshold=0.001)), ('mlpclassifier', MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.0...=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))])\n",
      "{'mlpclassifier__activation': 'relu', 'mlpclassifier__solver': 'adam', 'selector__threshold': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print (estimator.best_estimator_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ivcmC_O49522"
   },
   "source": [
    "##Optimizing Adam\n",
    "We will try now to optimize adam solver, by creating a GridSearch for the other parameters. For example, we will increase the hidden neurons in the first layer. Moreover, we will not change max_iter since we don't reach the default 200 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hc9rgl_75rII"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "#pca = PCA()\n",
    "clf = MLPClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'selector__threshold': [0.001],\n",
    "    'mlpclassifier__activation': ['relu'],\n",
    "    'mlpclassifier__solver': ['adam'],\n",
    "    'mlpclassifier__hidden_layer_sizes': [(100,),(150,),(200,)]\n",
    "    #'mlpclassifier__max_iter': [200,250,300]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ekaPfghv_G9M"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBwOJwDN--vj"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "NGA1-Cc1_Mwl",
    "outputId": "22d4f296-47aa-454b-c91b-8e930ce6488c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    7.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   55.9s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 1.60238885084788 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.96      0.97        48\n",
      "           2       1.00      0.97      0.98        30\n",
      "           3       0.97      0.89      0.93        36\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       1.00      1.00      1.00        38\n",
      "           6       0.94      0.94      0.94        32\n",
      "           7       1.00      1.00      1.00        29\n",
      "           8       1.00      0.98      0.99        47\n",
      "           9       0.86      0.89      0.87        27\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       324\n",
      "   macro avg       0.95      0.95      0.95       324\n",
      "weighted avg       0.96      0.95      0.95       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "print(\"Fit done in:\",(time.time() - start_time)/60,\"minutes\")\n",
    "preds = estimator.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "jdRZgFlv_RGU",
    "outputId": "6244de7c-b619-400f-93f7-9fa3ac359841"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='tmp',\n",
      "     steps=[('selector', VarianceThreshold(threshold=0.001)), ('mlpclassifier', MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(200,), learning_rate='constant',\n",
      "       learning_rate_init=0.0...=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))])\n",
      "{'mlpclassifier__activation': 'relu', 'mlpclassifier__hidden_layer_sizes': (200,), 'mlpclassifier__solver': 'adam', 'selector__threshold': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print (estimator.best_estimator_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BDiV68F-o-BO"
   },
   "source": [
    "Furhermore, we can read [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) some more information about adam and how to optimize the solver. For example we read about alpha that: The proportion that weights are updated (e.g. 0.001). Larger values (e.g. 0.3) results in faster initial learning before the rate is updated. Smaller values (e.g. 1.0E-5) slow learning right down during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7yDOI1GA95v"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "#pca = PCA()\n",
    "clf = MLPClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'selector__threshold': [0.001],\n",
    "    'mlpclassifier__activation': ['relu'],\n",
    "    'mlpclassifier__solver': ['adam'],\n",
    "    'mlpclassifier__hidden_layer_sizes': [(200,),(250,),(300,)],\n",
    "    #'mlpclassifier__max_iter': [250,260],\n",
    "    'mlpclassifier__alpha': [1.0E-5, 0.001, 0.3]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "05BUcW4csL7n"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sGQCe5A7sPwf"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "jnlT-FNSsUrX",
    "outputId": "5e55fe56-5820-492a-8c3a-c852820fb279"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   30.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  5.8min finished\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 5.942662898699442 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.96      0.98        48\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       0.97      0.92      0.94        36\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       1.00      1.00      1.00        38\n",
      "           6       0.94      0.94      0.94        32\n",
      "           7       0.97      1.00      0.98        29\n",
      "           8       1.00      0.98      0.99        47\n",
      "           9       0.88      0.85      0.87        27\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       324\n",
      "   macro avg       0.95      0.95      0.95       324\n",
      "weighted avg       0.96      0.96      0.96       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "print(\"Fit done in:\",(time.time() - start_time)/60,\"minutes\")\n",
    "preds = estimator.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "Px3oAytQsz6K",
    "outputId": "ab0feae2-4f7a-4c2a-baa0-af0397f7aaeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='tmp',\n",
      "     steps=[('selector', VarianceThreshold(threshold=0.001)), ('mlpclassifier', MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(300,), learning_rate='constant',\n",
      "       learning_rate_init=0.00...=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))])\n",
      "{'mlpclassifier__activation': 'relu', 'mlpclassifier__alpha': 1e-05, 'mlpclassifier__hidden_layer_sizes': (300,), 'mlpclassifier__solver': 'adam', 'selector__threshold': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print (estimator.best_estimator_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9yW92qB82GUy"
   },
   "source": [
    "Trying to further optimize Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAa2nDgI1kUk"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "#pca = PCA()\n",
    "clf = MLPClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'selector__threshold': [0.001],\n",
    "    'mlpclassifier__activation': ['relu'],\n",
    "    'mlpclassifier__solver': ['adam'],\n",
    "    'mlpclassifier__hidden_layer_sizes': [(325,),(330,),(335),(340,)],\n",
    "    #'mlpclassifier__max_iter': [260, 270, 280],\n",
    "    'mlpclassifier__alpha': [1.0E-5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t77HNXlg2pdp"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8AHhaKHz2v92"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "ANKrOuqN21Dx",
    "outputId": "d958360b-c8e5-4bc2-d530-3edc9ae50bdf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   39.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  3.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 3.1941980004310606 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.96      0.97        48\n",
      "           2       1.00      0.97      0.98        30\n",
      "           3       0.97      0.92      0.94        36\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       1.00      1.00      1.00        38\n",
      "           6       0.94      0.94      0.94        32\n",
      "           7       0.97      1.00      0.98        29\n",
      "           8       1.00      0.98      0.99        47\n",
      "           9       0.88      0.85      0.87        27\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       324\n",
      "   macro avg       0.95      0.95      0.95       324\n",
      "weighted avg       0.96      0.95      0.95       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "print(\"Fit done in:\",(time.time() - start_time)/60,\"minutes\")\n",
    "preds = estimator.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "m0zWQZbk26kx",
    "outputId": "cbf7f227-8c3c-48e8-ae89-43b3923d9904"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='tmp',\n",
      "     steps=[('selector', VarianceThreshold(threshold=0.001)), ('mlpclassifier', MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(330,), learning_rate='constant',\n",
      "       learning_rate_init=0.00...=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))])\n",
      "{'mlpclassifier__activation': 'relu', 'mlpclassifier__alpha': 1e-05, 'mlpclassifier__hidden_layer_sizes': (330,), 'mlpclassifier__solver': 'adam', 'selector__threshold': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print (estimator.best_estimator_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5lUa8rI-4afi"
   },
   "source": [
    "##Optimizing lbfgs\n",
    "Although the adams results are satifying we will see if can do better by optimizing lbfgs.\n",
    "\n",
    "This is because according to sklearn documents \"The default solver ‘adam’ works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, ‘lbfgs’ can converge faster and perform better.\" and here we have a relativly small training dataset with below 1000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qYAPZthB4WQJ"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "#pca = PCA()\n",
    "clf = MLPClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'selector__threshold': [0.001],\n",
    "    'mlpclassifier__activation': ['identity','logistic', 'tanh', 'relu'],\n",
    "    'mlpclassifier__solver': ['lbfgs'],\n",
    "    'mlpclassifier__hidden_layer_sizes': [(160,),(170,),(180,),(190,)],\n",
    "    #'mlpclassifier__max_iter': [260, 270, 280],\n",
    "    'mlpclassifier__alpha': [1.0E-5, 0.0001]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZjXthx-46ag"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gEVWgqrQ5ZV5"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "b4xnkG1S5eCm",
    "outputId": "24e4ec19-db41-4cba-cae1-98db14a4c9f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:   18.1s\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   35.6s\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:   53.2s\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 124 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 141 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:  2.6min finished\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 2.6184504707654317 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.96      0.96        48\n",
      "           2       1.00      0.90      0.95        30\n",
      "           3       0.94      0.92      0.93        36\n",
      "           4       0.89      0.89      0.89        37\n",
      "           5       1.00      1.00      1.00        38\n",
      "           6       1.00      0.91      0.95        32\n",
      "           7       0.91      1.00      0.95        29\n",
      "           8       1.00      1.00      1.00        47\n",
      "           9       0.84      0.96      0.90        27\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       324\n",
      "   macro avg       0.95      0.95      0.95       324\n",
      "weighted avg       0.95      0.95      0.95       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "print(\"Fit done in:\",(time.time() - start_time)/60,\"minutes\")\n",
    "preds = estimator.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "w-tYskmh5hOb",
    "outputId": "3ceb8098-0b60-40c2-dac4-6a611931218c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='tmp',\n",
      "     steps=[('selector', VarianceThreshold(threshold=0.001)), ('mlpclassifier', MLPClassifier(activation='identity', alpha=1e-05, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(190,), learning_rate='constant',\n",
      "       learning_rate_init=...True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))])\n",
      "{'mlpclassifier__activation': 'identity', 'mlpclassifier__alpha': 1e-05, 'mlpclassifier__hidden_layer_sizes': (190,), 'mlpclassifier__solver': 'lbfgs', 'selector__threshold': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print (estimator.best_estimator_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uiyNZWyW56c2"
   },
   "source": [
    "Although we alse get great results, they are not as good as adams. So, we will try to optimize further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V7fcvX0Q525n"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "#pca = PCA()\n",
    "clf = MLPClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'selector__threshold': [0.001],\n",
    "    'mlpclassifier__activation': ['identity'],\n",
    "    'mlpclassifier__solver': ['lbfgs'],\n",
    "    'mlpclassifier__hidden_layer_sizes': [(270,),(275,),(280),(290,),(300,),(320,)],\n",
    "    #'mlpclassifier__max_iter': [260, 270, 280],\n",
    "    'mlpclassifier__alpha': [1.0E-5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sTaEshB66SWK"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o6I6KO116Vwe"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "id": "iVRwbJbn6YvA",
    "outputId": "93bff1e7-1566-4bd6-8b36-8d1c7c871521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:   20.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   28.7s finished\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 0.5003676017125448 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      0.94      0.95        48\n",
      "           2       1.00      0.87      0.93        30\n",
      "           3       0.97      0.89      0.93        36\n",
      "           4       0.90      0.95      0.92        37\n",
      "           5       1.00      1.00      1.00        38\n",
      "           6       0.97      0.97      0.97        32\n",
      "           7       0.94      1.00      0.97        29\n",
      "           8       1.00      1.00      1.00        47\n",
      "           9       0.84      0.96      0.90        27\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       324\n",
      "   macro avg       0.95      0.95      0.95       324\n",
      "weighted avg       0.96      0.95      0.95       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "print(\"Fit done in:\",(time.time() - start_time)/60,\"minutes\")\n",
    "preds = estimator.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "Xcul2q4R6gBk",
    "outputId": "bc720b1c-42c3-4d08-e8ea-63b00f8aa27b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='tmp',\n",
      "     steps=[('selector', VarianceThreshold(threshold=0.001)), ('mlpclassifier', MLPClassifier(activation='identity', alpha=1e-05, batch_size='auto',\n",
      "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(300,), learning_rate='constant',\n",
      "       learning_rate_init=...True, solver='lbfgs', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))])\n",
      "{'mlpclassifier__activation': 'identity', 'mlpclassifier__alpha': 1e-05, 'mlpclassifier__hidden_layer_sizes': (300,), 'mlpclassifier__solver': 'lbfgs', 'selector__threshold': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print (estimator.best_estimator_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "To1UjN22lE2h"
   },
   "source": [
    "It is important to note that in order to do the more progressive tests at the neuros of the fisrt level, we started to increase gradually the neurons. However, here we present only some of the final results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gxss8dkj63GA"
   },
   "source": [
    "##Trying sgd\n",
    "Btween lbfgs and adam, the best one is currently adam. Since we already have great results with adam, we will not try to optimize further However we will also try sdg. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sm7fwsKb6j-i"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "#pca = PCA()\n",
    "clf = MLPClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'selector__threshold': [0,0.001],\n",
    "    'mlpclassifier__activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'mlpclassifier__solver': ['sgd'],\n",
    "    #'mlpclassifier__hidden_layer_sizes': [(140,),(160,),(180,)],\n",
    "    #'mlpclassifier__max_iter': [350],\n",
    "    'mlpclassifier__alpha': [1.0E-5],\n",
    "    'mlpclassifier__learning_rate': ['constant','invscaling','adaptive'] #it is only used for sgd    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RkXc7hSM8J5v"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vF_rq5YH8Pu5"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "4RCikmm18Swq",
    "outputId": "0c00eb55-1903-4f4e-acba-a14ef52efa41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:   19.8s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   45.9s\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  94 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 109 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed:  6.8min finished\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 6.878411356608073 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.92      0.96        48\n",
      "           2       0.88      1.00      0.94        30\n",
      "           3       0.85      0.94      0.89        36\n",
      "           4       0.90      0.73      0.81        37\n",
      "           5       1.00      0.95      0.97        38\n",
      "           6       0.84      0.81      0.83        32\n",
      "           7       0.96      0.86      0.91        29\n",
      "           8       1.00      0.87      0.93        47\n",
      "           9       0.60      0.93      0.72        27\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       324\n",
      "   macro avg       0.89      0.89      0.88       324\n",
      "weighted avg       0.91      0.89      0.89       324\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "print(\"Fit done in:\",(time.time() - start_time)/60,\"minutes\")\n",
    "preds = estimator.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "7ZMT-SHr8aMO",
    "outputId": "7e907163-2e18-46c0-a545-fdc9a813b6c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='tmp',\n",
      "     steps=[('selector', VarianceThreshold(threshold=0)), ('mlpclassifier', MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, m...e=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))])\n",
      "{'mlpclassifier__activation': 'tanh', 'mlpclassifier__alpha': 1e-05, 'mlpclassifier__learning_rate': 'adaptive', 'mlpclassifier__solver': 'sgd', 'selector__threshold': 0}\n"
     ]
    }
   ],
   "source": [
    "print (estimator.best_estimator_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EdZ1eZEysMaH"
   },
   "source": [
    "We will increase the max iter beacause we reached the limit and try to optimize further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJqsvM2Mr0AG"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "#pca = PCA()\n",
    "clf = MLPClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'selector__threshold': [0],\n",
    "    'mlpclassifier__activation': ['tanh'],\n",
    "    'mlpclassifier__solver': ['sgd'],\n",
    "    'mlpclassifier__hidden_layer_sizes': [(140,),(145,)],\n",
    "    'mlpclassifier__max_iter': [500],\n",
    "    'mlpclassifier__alpha': [1.0E-5],\n",
    "    'mlpclassifier__learning_rate': ['adaptive'] #it is only used for sgd    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D3W3rsSqsBze"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P0iAIjThsEb1"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 479
    },
    "colab_type": "code",
    "id": "JrwhLkTVsGrS",
    "outputId": "25528d94-da9c-4b5c-e679-a202ab32b5f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  2.6min finished\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 2.974272918701172 minutes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.98      0.90      0.93        48\n",
      "           2       0.88      0.93      0.90        30\n",
      "           3       0.94      0.86      0.90        36\n",
      "           4       0.87      0.89      0.88        37\n",
      "           5       1.00      0.97      0.99        38\n",
      "           6       0.82      0.84      0.83        32\n",
      "           7       0.96      0.90      0.93        29\n",
      "           8       0.98      0.94      0.96        47\n",
      "           9       0.71      0.93      0.81        27\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       324\n",
      "   macro avg       0.90      0.91      0.90       324\n",
      "weighted avg       0.91      0.91      0.91       324\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "print(\"Fit done in:\",(time.time() - start_time)/60,\"minutes\")\n",
    "preds = estimator.predict(test)\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "E8c88vV4tHhK",
    "outputId": "037bf8b3-a41b-49cf-eb29-0f1d6265eacb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory='tmp',\n",
      "     steps=[('selector', VarianceThreshold(threshold=0)), ('mlpclassifier', MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(145,), learning_rate='adaptive',\n",
      "       learning_rate_init=0.001, m...e=True, solver='sgd', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False))])\n",
      "{'mlpclassifier__activation': 'tanh', 'mlpclassifier__alpha': 1e-05, 'mlpclassifier__hidden_layer_sizes': (145,), 'mlpclassifier__learning_rate': 'adaptive', 'mlpclassifier__max_iter': 500, 'mlpclassifier__solver': 'sgd', 'selector__threshold': 0}\n"
     ]
    }
   ],
   "source": [
    "print (estimator.best_estimator_)\n",
    "print (estimator.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Y2RIOyQEi5E"
   },
   "source": [
    "##Results\n",
    "Having run multiple version of sgb (we only presented here the bests), no matter how much we increase the max_iter or the hidden neurons, it will not reach the adams's scores. So, cleartly the solver that gives the best results in our case is Adam. So we will run the Optimized MLPClassifier with Adam, one final time, to get the times that we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RSSHco91FFWd"
   },
   "source": [
    "##Final MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tgaYKuQIEiNV"
   },
   "outputs": [],
   "source": [
    "# αρχικοποιούμε τους εκτιμητές (μετασχηματιστές και ταξινομητή) χωρίς παραμέτρους\n",
    "selector =VarianceThreshold()\n",
    "#pca = PCA()\n",
    "clf = MLPClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'selector__threshold': [0.001],\n",
    "    'mlpclassifier__activation': ['relu'],\n",
    "    'mlpclassifier__solver': ['adam'],\n",
    "    'mlpclassifier__hidden_layer_sizes': [(330,)],\n",
    "    #'mlpclassifier__max_iter': [260],\n",
    "    'mlpclassifier__alpha': [1.0E-5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kW-x_chAAxQx"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[('selector', selector), ('mlpclassifier', clf)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9jLWA8ChFpho"
   },
   "outputs": [],
   "source": [
    "# We will use 5 fold validation\n",
    "estimator = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='f1_micro', n_jobs=-1, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "tsubGcwUFtLE",
    "outputId": "911967b6-0468-49e4-8f21-c53306b8fba0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   20.8s remaining:   13.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   26.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   26.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit done in: 31.86393666267395 seconds\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.96      0.98        48\n",
      "           2       1.00      1.00      1.00        30\n",
      "           3       0.97      0.92      0.94        36\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       1.00      1.00      1.00        38\n",
      "           6       0.94      0.94      0.94        32\n",
      "           7       1.00      1.00      1.00        29\n",
      "           8       1.00      0.98      0.99        47\n",
      "           9       0.85      0.85      0.85        27\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       324\n",
      "   macro avg       0.95      0.95      0.95       324\n",
      "weighted avg       0.96      0.96      0.96       324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "estimator.fit(train, train_labels)\n",
    "total_time = (time.time() - start_time)\n",
    "\n",
    "train_time_optimized['MLPClassifier'] = total_time\n",
    "print(\"Fit done in:\",total_time,\"seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "preds = estimator.predict(test)\n",
    "total_time = (time.time() - start_time)\n",
    "\n",
    "predict_time_optimized['MLPClassifier'] = total_time\n",
    "\n",
    "\n",
    "print (classification_report(test_labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "q-sOgtvMGSke",
    "outputId": "348c286e-6371-43bd-f965-fd9dea3f657c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dummy': 0.002794981002807617, 'GaussianNB': 0.027896642684936523, 'kNN': 0.01602029800415039, 'MLPClassifier': 5.070923566818237}\n",
      "{'Dummy': 0.002794981002807617, 'GaussianNB': 0.02132248878479004, 'kNN': 0.4556434154510498, 'MLPClassifier': 0.0045201778411865234}\n",
      "{'Dummy': 0.002794981002807617, 'GaussianNB': 0.30923914909362793, 'kNN': 1.4826996326446533, 'MLPClassifier': 31.86393666267395}\n",
      "{'Dummy': 0.002794981002807617, 'GaussianNB': 0.015270471572875977, 'kNN': 0.21165895462036133, 'MLPClassifier': 0.005356550216674805}\n"
     ]
    }
   ],
   "source": [
    "print(train_time_default)\n",
    "print(predict_time_default)\n",
    "print(train_time_optimized)\n",
    "print(predict_time_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "y-fmtpjPFtG9",
    "outputId": "cd701324-ff08-4c1a-cfe6-e2892bfb14ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dummy': 0.10209728647571724, 'GaussianNB': 0.8757800246079528, 'kNN': 0.8197525187183499, 'MLPClassifier': 0.9516176295439536}\n",
      "{'Dummy': 0.10209728647571724, 'GaussianNB': 0.8757800246079528, 'kNN': 0.875220366720062, 'MLPClassifier': 0.9540284066843733}\n",
      "{'Dummy': 0.10185185185185185, 'GaussianNB': 0.8827160493827161, 'kNN': 0.8364197530864198, 'MLPClassifier': 0.9537037037037037}\n",
      "{'Dummy': 0.10185185185185185, 'GaussianNB': 0.8827160493827161, 'kNN': 0.8796296296296297, 'MLPClassifier': 0.9567901234567902}\n"
     ]
    }
   ],
   "source": [
    "report_dict = classification_report(test_labels, preds, output_dict = True)\n",
    "f1_macro_optimized['MLPClassifier'] = report_dict['macro avg']['f1-score']\n",
    "f1_micro_optimized['MLPClassifier'] = report_dict['micro avg']['f1-score']\n",
    "\n",
    "print(f1_macro_default)\n",
    "print(f1_macro_optimized)\n",
    "print(f1_micro_default)\n",
    "print(f1_micro_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q0dGAmmMIyTo"
   },
   "source": [
    "#Final Results and Comparisons\n",
    "Since, we have run and taken all the metrics we need from multiple Classifiers, we can now plot them and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "vQ8QtnJ_9OtL",
    "outputId": "46bfb751-0c8a-4787-d821-03093757c490"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time in (s):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>MLPClassifier</th>\n",
       "      <th>kNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>0.002795</td>\n",
       "      <td>0.027897</td>\n",
       "      <td>5.070924</td>\n",
       "      <td>0.01602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimized</th>\n",
       "      <td>0.002795</td>\n",
       "      <td>0.309239</td>\n",
       "      <td>31.863937</td>\n",
       "      <td>1.48270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dummy  GaussianNB  MLPClassifier      kNN\n",
       "default    0.002795    0.027897       5.070924  0.01602\n",
       "optimized  0.002795    0.309239      31.863937  1.48270"
      ]
     },
     "execution_count": 238,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = [train_time_default, train_time_optimized]\n",
    "print(\"Train time in (s):\")\n",
    "pd.DataFrame(times, index=['default', 'optimized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "O23k7B94-76K",
    "outputId": "69c59b2e-648f-4ddb-98a5-a3aaf22cbc5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict time in (s):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>MLPClassifier</th>\n",
       "      <th>kNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>0.002795</td>\n",
       "      <td>0.021322</td>\n",
       "      <td>0.004520</td>\n",
       "      <td>0.455643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimized</th>\n",
       "      <td>0.002795</td>\n",
       "      <td>0.015270</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.211659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dummy  GaussianNB  MLPClassifier       kNN\n",
       "default    0.002795    0.021322       0.004520  0.455643\n",
       "optimized  0.002795    0.015270       0.005357  0.211659"
      ]
     },
     "execution_count": 239,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times = [predict_time_default, predict_time_optimized]\n",
    "print(\"Predict time in (s):\")\n",
    "pd.DataFrame(times, index=['default', 'optimized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "E6PTJ-mrtxDO",
    "outputId": "96e7ce28-4f64-4a3b-bda7-3ab6e111a369"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFZCAYAAAC173eYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a1dc578d0>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 4\n",
    "time_default = list(train_time_default.values())\n",
    "\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.4       # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, time_default, width, color='m')\n",
    "\n",
    "time_optimized = time_optimized = list(train_time_optimized.values())\n",
    "\n",
    "rects2 = ax.bar(ind + width, time_optimized, width, color='c')\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('Train time (s)')\n",
    "ax.set_title('Train time default vs optimized (s)')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(list(train_time_default.keys()))\n",
    "\n",
    "ax.legend((rects1[0], rects2[0]), ('default', 'optimized'))\n",
    "\n",
    "# Turn on the grid\n",
    "#ax.minorticks_on()\n",
    "#ax.grid(which='major', linestyle='-', linewidth='0.5', color='red')\n",
    "# Customize the minor grid\n",
    "#ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.01*height,\n",
    "                \"{:.4f}\".format(height),\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ce1eJ_Qqu-3X"
   },
   "source": [
    "It's clear that MLPClassifier needs the most time in training both when default and optimized. In each classifier the increased time is due to the pipe, beacause we first need to apply the Variance Theshold. In MLPClassifier, the huge increase of fit time, apart from the pipe, is a result of the logistic activation function, the increase of the hidden neuros at the first hidden layer and the dicrease of alpa, which needs more time to converge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "SxR-jPaYj-9Y",
    "outputId": "c1b8cb59-4f03-4a61-89ed-d0c0d2a79b31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 micro scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>MLPClassifier</th>\n",
       "      <th>kNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>0.101852</td>\n",
       "      <td>0.882716</td>\n",
       "      <td>0.953704</td>\n",
       "      <td>0.83642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimized</th>\n",
       "      <td>0.101852</td>\n",
       "      <td>0.882716</td>\n",
       "      <td>0.956790</td>\n",
       "      <td>0.87963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dummy  GaussianNB  MLPClassifier      kNN\n",
       "default    0.101852    0.882716       0.953704  0.83642\n",
       "optimized  0.101852    0.882716       0.956790  0.87963"
      ]
     },
     "execution_count": 241,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores = [f1_micro_default, f1_micro_optimized]\n",
    "print(\"F1 micro scores:\")\n",
    "pd.DataFrame(f1_scores, index=['default', 'optimized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "zOPKKwLZkH1M",
    "outputId": "1d40ded7-fec2-4e38-d0dc-3ee8042eb082"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFZCAYAAACxGqelAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3XdclXX/x/HXAURFEEFA3Ctx5h6Z\nlTt3mSOxRO/blpnlHqmJC1dq7hxNt2bc/rRMLbXlHreipOUWLBUElSMgAtfvD25PnkCk5KgXvp+P\nR4+49uc63+N5X/uyGIZhICIiIqbh9KALEBERkb9H4S0iImIyCm8RERGTUXiLiIiYjMJbRETEZBTe\nIiIiJqPwFlMpX748zZs3p2XLlrb/XnnlFdvwn3/+mfr16zNv3rx7XtaQIUPYunXrPc/HDPbt20eT\nJk3uOt6yZcto0KABH3744T9azu7du2nevDkA0dHRbNmy5R/NxxFWr15t+7tHjx6Eh4dnedqwsDC7\n7+G9qlSpEpGRkdk2P8l5XB50ASJ/15IlS/D390/Xf/369SxbtoxKlSply3KmTJmSLfPJSTZv3ky/\nfv3o3LnzPc9r9+7d7Nixg6ZNm2ZDZfcmJSWFKVOm8OKLLwLw+eef/63pq1atyscff+yI0kQypD1v\nyTHKlCnD4sWL8fX1zXS8YcOG8cEHHxAUFMQTTzzB9OnT+eKLL2jXrh1NmjQhLCwMgKCgIP7v//4P\ngB9//JE2bdrQokUL3njjDa5cuQKkHQlYsGABLVq0ICUlhWPHjhEYGEjLli15/vnn+emnnzKsYenS\npbRq1YqWLVvSqVMnjh8/DsCRI0fo0KEDLVq0oFu3bkRERADccb67d+8mMDCQvn37MnDgQAC+++47\n2rVrR9OmTenZsycxMTEZ1jBv3jwaNmxI+/bt2bFjh61/UlIS48ePp0WLFjRp0oT58+cDaRszBw8e\nZObMmcyePZuEhAT69etnG2/y5Mm2eTRp0oR9+/bdsTs8PJyxY8eyadMm+vfvb1fXsmXL6NWrl607\nJSWFevXqcfLkSb755hvatm1Lq1ataNeuHbt37063XqmpqXzwwQe2IzPDhg0jPj7eVseiRYvo0KED\nTzzxBDNmzADg3//+N3FxcbRs2ZKIiAhbvZGRkTz11FMsWrSIFi1a0KJFCw4ePMjrr7/O008/zbvv\nvmtrh1tHFIKCgmzLfuaZZ6hXr16mnyvADz/8QPPmzWnVqhUfffRRhu0lYscQMZGAgADjjz/+yHSc\noUOHGnPnzs10ePv27Y3r168bv/76q1GxYkVj/vz5hmEYxqRJk4xBgwYZhmEY3bp1M9auXWtcv37d\nqFu3rvHrr78ahmEY48ePN0aPHm2r58MPPzQMwzBSUlKMVq1aGevXrzcMwzDCwsKMOnXqGHFxcXbL\nj4uLM2rXrm3rv2HDBmPhwoWGYRhG8+bNje+//94wDMP49NNPjddeey3T+e7atct4/PHHjR07dhiG\nYRjnzp0zatSoYat1/vz5xttvv53uMzh+/LhRp04dIyoqykhOTjZ69+5tNG7c2DAMw5gzZ47Ro0cP\n48aNG8b169eN9u3bG1u3brX7TAzDMD7++GPj1VdfNVJTU40rV64YdevWNfbu3WsYhmE0btzY9vft\n3bt27TKaNWtmGIZhzJo1yxg+fHi62i5dumRUr17diI+PNwzDMHbu3Gm0bdvWMAzDqFevnhEZGWkY\nhmHs3bvXmDBhQrrpv/rqK1v7JicnG2+++abt+9C4cWOjd+/eRnJyshEdHW3UqVPHOHr0qBEREWFU\nrFgxXb0RERFGpUqVjP/85z+GYRjG22+/bTRq1Mi4fPmyERMTY1SpUsU4e/as3XrdkpqaavTs2dP4\n5JNPMv1ck5OTjQYNGhg//fST7XMNCAgwIiIi0q2byC3a8xbTuX3PpmXLlowcOfJvz+PJJ5/Ezc2N\ncuXKkZqaSuPGjQEICAjg0qVLduMeOHAAf39/AgICABg8eLBtjwugUaNGAERGRhIdHU2bNm0AePzx\nxylSpAiHDx+2m1/u3LmxWCysWbOG6OhoWrVqxWuvvcbp06eJjY2lYcOGAHTr1o3Zs2ffdb558uSh\nfv36QNoRgrp169pqDQwMZOvWraSkpNjVsHfvXurUqYOPjw/Ozs4899xztmHbtm3jpZdewtXVFTc3\nN55//nk2b96c7jPs2bMn8+bNw2Kx4OnpSbly5bLlPK2vry+VKlVi+/btQNqRhFatWgFQsGBBVq5c\nyfnz56ldu7ZdO9zy/fff0759e9zc3HB2dqZDhw62eQG0b98eZ2dnChYsSK1atThw4ECm9SQnJ9Oy\nZUsg7fvx+OOP4+3tjZeXF76+vum+L7d8/PHHODk58a9//Qu48+d65swZkpKSeOqppwB44YUX/t4H\nJo8knfMW07nTOe+/I1++fABYLBacnJxwc3MDwMnJidTUVLtxY2NjyZ8/v63b1dXVbniBAgUAiImJ\nwcPDA4vFYhuWP3/+dIetc+XKxWeffcb8+fOZPXs25cuXJzg4mOvXr+Ph4WEbz8XFBRcXl0zn6+Pj\ng6enp61/XFwc+/bts4UNgLu7O1euXKFgwYK2flevXrVb1u3rFxcXx8SJE5k+fTqQdri3atWq6T7D\nM2fOMGnSJE6dOoWTkxMXLlygQ4cO6cb7J1q0aMHWrVtp1qwZW7Zs4dNPPwXgww8/5MMPP6RDhw4U\nLlyY4cOHU7duXbtpY2Ji7D4TT09PLl++bNd9+9/Xrl3LtBZnZ2fy5MkDYPdduTXsrxtGAIcPH2bp\n0qV8+eWXtna70+d69epV3N3dM6xP5E4U3iJ34eXlRWxsrK07ISGBq1evptuAKFiwIFevXsUwDNsP\n9l9D85ZKlSoxa9YskpKS+OijjwgODmbixIlcuXKF1NRUnJycuHnzJhcvXvxb8/Xz8+PJJ59k1qxZ\nma5T/vz5iYuLs3Xfvn5+fn707NnTdjTiTsaOHUvlypWZO3cuzs7OBAYG2ob9dSPo6tWrmc7rr1q0\naMGCBQs4fPgwnp6elCpVCoASJUowceJEUlNTWbt2LQMHDkx3XYGPj4/tmgRI+6x8fHwyXNcrV65k\ne1harVYGDRpESEiIXRvd6XM9efIkVqvV1n2naxREbqfD5iJ3UatWLaKiomwXss2bN4+5c+emG69Y\nsWL4+/uzYcMGIO1we3R0dLq91l9//ZV33nmHpKQkXF1dqVKlChaLhVKlSuHv7287RL1mzRpGjRqV\n5fkCPPXUU+zbt892oVtYWBjjx49PN16NGjXYv38/MTExpKSksG7dOtuwpk2b8sUXX5CSkoJhGMyb\nN48ff/wx3TwuX75MxYoVcXZ2Zvv27Zw9e9Z2YZivry/Hjh0DYMOGDdy4cSPd9C4uLnYbELcrVKgQ\nxYsXZ/78+bZD5jExMfz73//GarXi5OREtWrV7I5G3NKoUSPWrVtHQkICycnJrFmzxnYq4lY9qamp\nREdHc+DAAWrXrk2uXLlITU21C9F/asyYMTRt2pQGDRrY9b/T51qiRAmcnZ1tF9+FhoZmuF4it9Oe\nt+QY7777Lv/973+JiooiV65crFu3jm7dutGtW7d7mm/evHmZPXs2gwcPBqBkyZJMmjQp3XgWi4Xp\n06cTHBzMnDlzyJs3LzNnzrQ7zApp502LFStG27ZtyZUrF/ny5WPUqFFYLBZmzpzJ4MGDmT59Or6+\nvkycODHL84W0vbtx48bx1ltvcfPmTfLly8fw4cPTjVexYkUCAwN54YUXKFCgAG3atOG3334D4KWX\nXiIyMpI2bdpgGAZVqlShR48e6ebx5ptvMnHiRObNm0fTpk3p06cPs2bNomLFivTu3Zvg4GBWr15N\nixYteOyxx9JN36BBAz799FM6duzIl19+mW54ixYtmDRpEkOHDgXA29ubp59+mo4dO+Ls7EyuXLkI\nCQlJN13Lli359ddf6dChA4ZhUK9ePbp3724bXq5cOTp16sT58+cJCgqyXfdQq1YtGjduzIIFC9LN\nM6v++OMP1q1bR4kSJeyeEbBo0aI7fq65cuVi3LhxDB8+HFdXVzp06JBh24rczmIYep+3iDwamjRp\nwpQpU6hdu/aDLkXknuiwuYiIiMkovEVERExGh81FRERMxqF73r/99hvNmjVj6dKl6Ybt2LGDTp06\n0aVLlwyv3BUREZGMOSy84+PjGTdunO3JT381fvx4Zs+ezYoVK9i+fTsnTpxwVCkiIiI5isNuFXN1\ndWXRokUsWrQo3bCIiAg8PT0pXLgwAA0bNmTnzp0Z3k5yS1RUxveDPgq8vNyIjY1/0GVIFqitzENt\nZR5/bav9+/cyd+4M4uMT8Pf3Z/jwYPz8CtlNs2vXDubPn4PVGkfp0mV4772x5M/vyYYN65k5cyoF\nC/754J6OHV+kY8cuAPznP2tYvnwxAHXq1GPAgKG4uLgQHn6EGTPe5/p1K3ny5OW113pRv/5TDl93\nX1+PDPs7LLxvPdoxI1FRUXh7e9u6vb29bQ+VuBMvLzdcXJyztUYzuVMDysNHbWUeaqs/7dy5kylT\nphAfH0+RIkWYOHFiuqcI/vjjj0ybNo24uDgee+wxpkyZQoECBQgNDSUkJMTujX63nrEQFxfHqFGj\nOHr0KIZh0KpVK/r168fvv/9Oz5497eb/xx9/8MEHH2T4bvlbbRUfH8+YMSP46KOPqFy5MosXL2bW\nrPft7s+PiYlh7NiRLF68mIoVKzJt2jQ+/ngeEyZMwMMjD88++2yGz2rYt28fa9asIDT0S/Lnz8/Q\noUM5d+436taty6hRQxk3bhwNGzbkt99+46WXXmLbtm12jxm+n0zzkJZHeQvZ19fjkT7yYCZqK/NQ\nW/0p7fWu/Zk2bTbly1fgiy9W8u67I5gyZYZtnNjYWPr3H8Ds2fMpV6488+fPYezYEN59dxRxcYk8\n/XQjRowYbTffqKg4pkwJwd3dkyVLviAuLo6ePbtRpkx56td/iiVLvrCNe+HCH/Tr9xYBAY+na5fb\n2+rnn3/E378Ifn4liIqKo2HDFkyePJmzZy/g5pbvf+PsoGjRYvj4FCMqKo527TrRtWsH+vd/l7i4\nRBITb2bY9suXr6JNm/akpOQiNjaBYcPS1ufUqfNcvHiRxx6rQlRUHF5ehXF1zc3hw79Srlz57GiC\nO7rTBuYDuVXMz8+P6OhoW/fFixfx8/N7EKWIiDzy9u/fS5EiRSlfvgIAbdo8x549u4iPv24bJzw8\njOLFi9vCqkuXl/jhh60Zzu92jRo15eWX057Q5+HhQfny5Tl37my68ebNm8W//vUKuXPnyXR+ERHn\nKFq0mK3bzc0NT09PIiNvP3prISXlz2fr58mTF6vVanvm/fHjv9Gnz+sEBnZg4sSxtsfinjhxnISE\neHr3fpWuXTuwYMFcUlJSyJ/fk4CA8nz77UYADh06iLOzMyVLlr7r+jvKAwnvYsWKYbVaiYyMJDk5\nmW3btqV7DrCIiNwfjgzEunWfsJ1fPnfuLEeP/kKdOk/YLf/UqRP89tsxnn221V1rvXEjMd2b/Vxd\n85CQkGjrrlKlKpGREezbtwfDMFi1ahnOzs4kJd2gePESPP10Q6ZM+YDPPlvO9evXmTVrGgBWaxxh\nYYeYOnUmH374CTt2/MSGDesBGDJkJHPmzKBVqyb079+b/v0Hp6vjfnLYYfMjR44wefJkzp8/j4uL\nC5s2baJJkyYUK1aM5s2bM3r0aAYOHAhA69atKV36wW3BiIg8yv5uINaqVSfDQOzatRtOTs6MHx/M\nrFnTGD48GICUlBReeqkjly9H8+ab71CmTFm7ZS1fvoTOnbvi5HT3/ck8efKQlJSUrn43t7y27gIF\nCjB27ETmzZtJcnIybdu2J3fuPLi7u+PnV43HH69mGzco6N8MHPg2APnyudO8+bO4ueXDzQ1atWrL\nnj27ePbZlgwfPohx4yZRu3ZdTp8+xTvv9KJcufL4+xfO4qecvRwW3lWqVGHJkiV3HF6nTh1WrVrl\nqMWLiEgWOTIQIe2956tWrSU2Npbhwwfi7OxE+/adgLT3mv/00/e89Va/LNVasmQptmz51tZttVqJ\ni7tGsWIl7MZ74okneeKJJ4G08+lffLECN7d8XLx4AVfX3Hh5eQGQkpJsu7ja37+w3ZvlnJyccXJy\n4vTpU6SmplK7dtq740uXLkOxYsX55ZfwBxbeejyqiMgjrmTJUnaHyDMLxE8+Wcbixat45plGeHp6\n2gLx9vek3x6IGzd+bXv1q5eXF02bPsvu3Ttt4/73v/spWbK0LUzvpmbN2ly8eIFDhw4CsGrVMp58\n8iny5v1zQ+P6dStdu3bgwoULGIbBZ599RKtWbQFYu/ZLpkwZT3JyMikpKXz55SrbLV9NmzZn/fq1\nWK1WbtxIZPPmb6hTpy6FChXGao3j6NFwAC5cuMDp06coVeoRO+ctIiIPD0cG4oYN61m9ejkAycnJ\n7Nmzi7Jly9nme+LEb38rBHPnzsPo0SFMnz6ZLl3aEx5+hAEDhhIVdYmgoBeBtMPfXbq8xNtvv06n\nTu0A6N497ba0Hj1ewd3dg27dOtOtW2ecnV14662+ADRt+iyNGzeje/cu9OjxEjVq1KJVq3Z4eXnx\n3ntjmTRpHF27dmDgwD707p3+8P/9ZJpnm5vhlo74+Hi6d+/CmjXrMxw+dGh/EhISmDVrfpbnuWHD\nei5ciKBnz95s2/YdjRs3y65yxQF0+5F5qK3sHTiwj5kzp5GYmEDRosUZMSKY1NRUBgzow5IlqwFY\nu3YNy5YtJjU1lTp16jFo0Lu4uLiQmJjItGmTOHz4EBaLhccfr8Y77wzE3d2dCxf+YOrUifz++3lS\nUlJ4/PFqDBw4zLZhMGPG++TJk5devfrcsbZHua3udKtYjgpvv3n5s3WZl3pf+1vj3y28W7ZszMaN\n2/7WPG8P71deCeLjj+98HYE8eI/yj4zZqK3M41Fuq/v+hLVHxfXrVkaMGEJSUhJVq1YH4NCh/7Jg\nwVxcXFzw8yvE0KEjmT9/DgkJ8Qwc+A5jx05gzJiRJCQkkJiYSP/+g6lUqQqdOrVj8eJVuLm5MWfO\nDLtDMsuXL+bEid8YPnwwEya8/6BWV0REHgI6532PNm36hjJlyjJv3keUKxcApB0GmjRpGrNmzcfb\n25tt277j7bf74+7uzrRps7h8+TJt27Zn9uwF9OrVh2XLPr/rcl56qTvu7u4KbhER0Z73vTpz5hTV\nq9cCoEaNWsTExHD16hWGDx8MQGJiIp6eBeym8fYuyOeff8SKFUu4efMmefJk/kQhERGR2ym875Fh\ngJOTBYDUVINcuVzw9i7InDkL7zjN6tXL8fHx4733xnHs2C/MmZP2/GCLxWIbJzk52bGFi4iYRNpP\n48P/EplLl+7feXmF9z0qUaIkx44dpVGjphw4sA8Pj7SL5k6fPkXp0mVYs2Yl1avX4rHH/rw14urV\nK7ZbJX74YZstqN3c8nH5cjS5cxclPPwwAQH2D7xPTTXFtYUiYgLZfYGvY+m37690zvsetWzZhvDw\nw/Tt+yYREWexWCwMGzaKCRPG0Lv3q4SFHaJEiZLpplm1ahn9+79F5cpVuHz5Ml9/vY6OHV9k6ND+\njBgxmNKly6RbVkBAeV57rfv9WjUREXlI5ahbxXKqR/k2CbNRW5nHo95WptrzHm2KmHLIYfOH6pWg\nIiIi8s8pvEVERExG4S0iImIyCm8RERGT0a1iYkr79+9l7twZxMcn4O/vz/Dhwfj5FbIbZ8eOn1m4\ncB5JSTfw9PTk7bcHUKlSFVJSUpgzZwa7dm3HycmJypUfp1+/wbi5uREVdYn335/I+fMRGIZB585d\neeGFThw5EsaECWPs5n/+fCSffLKMsmUfM32dImIuutrcBB71q2L/KiEhgc6dn2PatNmUL1+BL75Y\nyd69u5gyZYZtnLi4ODp1asvcuR/x2GPl2LVrB1OmhBAa+jXr1v2HTZs28MEHac+fHzv2PYoUKcrr\nr/dmyJB+lC9fkVdeeYPo6Ci6dXuRhQs/pUSJUnY1hIcfYcaMKSxc+Lndw3Vub6uHuU5J/+/qXja0\n5s2byc8//2gbLzExkQIFvPjkk6VERkbw/vsTuHjxArlz52HEiGACAioAEB0dxfjxwURGRpAvXz76\n9x9C9eo178v662rz7KerzXOo77/fAqS9KeyHH7L2drFhwwbc0zJfeSWIP/74/Z7m8bDZv38vRYoU\npXz5tB/ANm2eY8+eXcTHX7eN8/vv58mTJ4/t4Ti1atXh0qWLxMXFcerUCR5/vBqurq44OTlRo0Yt\nTp8+CcBzz3Wgc+euAPj4+FKkSBHOnDmTroaZM6fSp0//TAPRLHVK2oZWcPBwhg59j5UrQ2nQ4Bmm\nTp1oN05cXBxjxoxg5MgxLF/+JT16vMrIkUMB6N27L8uXf2n778knn6Z167R3XY8ZM5JnnmnEypX/\noXfvdxg16l1u7TONHx/ME088yZo16+nbdxBffrn6/q64mFaOCm8/P49s/S87/fHH73z33SYAWrdu\nR8OGjbM03aRJ07O1jpwgIuIcRYsWs3W7ubnh6elJZGSErV+pUqVwcnJm//69AGzbtoUKFSrh4eFB\nrVp12LVrB9euXePGjRvs2PETtWvXA+Cpp54hf/60PZILFy4QEXHOtpd0y44dP5M7d26qVauRI+qU\ne9/Qut2pUyc4ePAA7dt34vp1K0ePhtO69XMA1KtXHxcXF06c+I2LFy/w66/H6NQpEICaNWszbtyk\n+7G6kgPonPc9Sk5OZsqUEH7//TxJSUm8+movpkwJoVWrtuzfv5dcuXIxfvwUpk+fzNGj4Xz66SJS\nU1MpUKAApUuX5YsvVuLs7Mxvvx2je/ee7N69k+PHf6V3774880wj2rRpyp49exg2bABWqxWAw4cP\n8eWXXxEXF8cHH0zBYrHg5ubG8OGj8fDwYMaM9zly5DAlSpQkOfnmA/6Est+NG4m4urra9XN1zUNC\nQqKtO3fuPAwZMpzBg/uRO3duDCOVqVNnA/D004344YdtPP98C1xcXAgIqMBzz71gN7+4uDhGjhxC\nUNC/8ff3txu2fPliXnrp7k+6M0udkvmG1q2Nots3tGrVqmO3oXW7Tz5ZxMsvd8fFxYWkpLQjHoaR\nahueN29eIiMjcHW9ROHCRfjww9ns2PETBQv68M47A9JthIlkJEfteT8I3367EVdXV+bMWciECe8z\nffoUAEqWLMW8eR/x2GMBfPPNV3TtGkT16jX5979fs5v+xInfGDVqHIMHv8v8+XMYPjyYQYPe5Ztv\n1tuNN2nSdObMWUjjxs144YVO+Pj4MmPG+wwePJyZMz+kTp0nCA1dzenTpzh8OIyFCz/jjTfe4ty5\ns/fts7hf8uTJQ1JSkl2/GzcScXPLa+uOjo5i0qRxLFr0Od98s5UJE6YyYsQg4uPj+eKLlVy5Ess3\n32zjm2+2UapUaWbOnGab9vLlaN555w3q129A9+497ZZz6dJFTp06Sb169XNMnfL3N7RatWrC9OmT\n6NdvsN00kZER/PLLEZo3bwmkva+gUqUqrFy5DMMw2Lt3N6dOnSQpKQmrNe3USPXqNVixIpRnn23F\niBFD9FIiyRKF9z369dej1KiR9kpQHx9fXF1zce3aNdvhzSpVHs80QB97rByurq4ULOhD8eIlyJs3\nL97e3ra97NudOnWSjRu/5s033wHgl1/CmTx5PH36vM6mTRuIjY3hzJlTVKpUBScnJwoV8qdIkaIO\nWOsHq2TJUnaHnq1WK3Fx1yhWrISt3+HDhyhSpKjtCuuaNWvj5OTM2bOn2bt3F88805g8efLg4uJC\no0ZNOXjwAADXr1sZMOBtWrZswyuvvJFu2Tt2/EydOnVxdnbOMXXKvW9o3bJly2aeeaYRLi5/HtQM\nDh7P4cOH6Nq1I1u3fkfVqtVxd/cgXz53vL0L8vTTjQBo1649165dJSLinGNXVnIEhfc9s3D7Bfs3\nb97EycliO0xmGGR6sdDtP663//3XmwBu3LjBxIljeffdUeTOnRtI+8GZPXsBc+YsZMGCT+nXb7Dd\nK0oBUlNTyWlq1qzNxYsXOHToIACrVi3jySefIm/eP39oixcvyenTp2wX6/366zGsVitFixajePGS\n7Nq1w7aHs3Pnz5QpUxaARYs+pFat2nTp8nKGyz5x4jglS5bOUXXKvW9o3bJjx8888UQDu3kXLVqM\nDz6Yy8qVoQwdOoLz5yMpW/Yx/P0LEx9/3fZv1GKxYLE44eysn2W5O53zvkcVK1biwIF9NGvWgosX\nL+Dk5IS7uweHDv2XRo2aEh4eRqlSpXFyciIlJeUfL2fevJm0atXW9uMN2G4tql+/Ad99t4kCBbwo\nUaIkq1cvxzAMLl68kOOuNIe0w5ejR4cwffpkEhMTKFq0OCNGBBMVdYkBA/qwZMlqHnusHL169WHQ\noHdITU3F1dWVUaPGkj+/J//616tMnz6Zl1/uhMXiRIkSJRg8eDgA//d/ofj4+LJr1w7b8l58sSvt\n23cCICrqot3rXXNCnZIWxBMnjuPQoYNUq1b9rhtahQsXsdvQuuXkyeOUKmW/0TR0aH9atWpLo0ZN\n2bjxawoV8sffvzCGYeDj48v69Wt5/vkObN36HR4e+SlSpBgid5Oj7vPO7ivEs3LPXnJyMlOnTuT8\n+UiSk2/yxht9GD8+mObNW/LLL0cACxMnvs+NG0m88ko3GjVqQr587rYL1kJDVzN+/BROnTrB9OlT\nmDNnod3fbdo0Zf369TRu3JjHH69mW+5rr/XG09OTKVNCcHJywtU1N6NHjyd//rR+J04cp3jxEpw7\nd4axYydRuHCRbP1sJGO6J988/tpWBw7sY+bMaXYbWqmpqbYNLYC1a9fwxRcrbRtar77ay3bY+9q1\nq7Ru3ZStW3fYnT8PCzvIlCkTuHHjBv7+/owcOYZChdIuLjx9+hQTJozmypWreHl5MWDAUCpUqHhf\n1l/3eWe/+3mfd44K74dFp07tWLx4FW5ubtkyPwWCeaitzONRbyuFd/bTQ1pERETkjnTO2wHWrFl/\n95FERET+Ie15i4iImIz2vOWhZ75zc9l74aSjOOL8XEbu5YUfAB9/vIAtWzaTmmoQEFCewYOH255q\n9p//rGH58sUA1KlTjwEDhtoxMQIdAAAgAElEQVTdYx0dHcXLL3eib99BtG7d7r6sr8j9oPAWEYe5\n9cKP29+sNnXqxHRvVhszZoTdm9VGjhxKaOjXfPvtRvbu3c2nny4jVy5XRo0axpIln9C7d18OHTrI\nqlXLWLjwczw8PBg/PpiwsIPUrFnbNu8ZM6bi4ZHxxl/a4xe0oSXmpMPmIuIw9/rCj1KlyjBw4DBy\n585je7ParScWbtiwjuee64CXlxcuLi6MHh1iF9w7d/5MYmKC7QmIIjmJwltEHOZe36xWrlwA5coF\nAGlPPdu2bQtPPfUMkPYUuYSEeHr3fpWuXTuwYMFc24OQEhMTmTt3Fv37D7lfqypyX+mwuYg4zL2+\nWe2W0aNH8NNP39OsWQtatkx7T7bVGkdY2CGmTp1JUtJN+vbtRZEiRWnXrj2ffrqI5s1b2G04iOQk\n2vMWEYfJrhd+jB4dwoYNW8mbNy9jx74HQL587jRv/ixubvkoUKAArVq1Zc+eXZw6dYLdu3fqdaiS\no2nPW0QcpmTJUmzZ8q2t++++8CM+Ph4vL2/KlClL7ty5adfuBd5661UA/P0L2719z8nJGScnJ7Zv\n/4lLly7SsWNb2zJ//HEbUVGX6NHjlfux2iIOpz1vEXGYe32zWljYQebM+cC29759+4+ULZt2YVvT\nps1Zv34tVquVGzcS2bz5G+rUqUtQ0L/ZsGEL69ZtYt26TTRt2py+fQcpuCVH0Z63iDjMvb5Z7aWX\nujN79nR69AjEMKBQoUIMHToSgKZNn+X06VN0794FV9fcPP10Q1q10r3c8mjQi0lMQC9QMNtDWszh\nUb93OLvfQuhIjmgr/bvKfnoxiYiIiNyRwltERMRkFN4iIiImo/AWERExGV1tLiLZxlQXQWGOi6BE\nMqI9bxEREZNReIuIiJiMwltERMRkFN4iIiImo/AWERExGYW3iIiIyTj0VrEJEyZw6NAhLBYLw4cP\np2rVqrZhy5YtY926dTg5OVGlShVGjBjhyFJERERyDIftee/Zs4ezZ8+yatUqQkJCCAkJsQ2zWq18\n/PHHLFu2jBUrVnDy5EkOHjzoqFJERERyFIeF986dO2nWrBkAZcuW5erVq1itVgBy5cpFrly5iI+P\nJzk5mYSEBDw9PR1VioiISI7isPCOjo7Gy8vL1u3t7U1UVBQAuXPn5q233qJZs2Y0btyYatWqUbp0\naUeVIiIikqPct8ej3v7acKvVyoIFC9i4cSPu7u706NGDY8eOUaFChTtO7+XlhouL8/0o9aF0p3e6\nivxT+k6Zh9rKHO5nOzksvP38/IiOjrZ1X7p0CV9fXwBOnjxJ8eLF8fb2BqB27docOXIk0/COjY13\nVKkPPV9fD6Kisv8l7/Jo03fKPNRW5uCIdrrTBoHDDps3aNCATZs2ARAeHo6fnx/u7u4AFC1alJMn\nT5KYmAjAkSNHKFWqlKNKERERyVEctudds2ZNKleuTGBgIBaLheDgYEJDQ/Hw8KB58+a88sordO/e\nHWdnZ2rUqEHt2rUdVYqIiEiO4tBz3oMGDbLrvv2weGBgIIGBgY5cvIiISI6kJ6yJiIiYjMJbRETE\nZBTeIiIiJqPwFhERMRmFt4iIiMkovEVERExG4S0iImIyCm8RERGTUXiLiIiYjMJbRETEZBTeIiIi\nJqPwFhERMRmFt4iIiMkovEVERExG4S0iImIyCm8RERGTUXiLiIiYjMJbRETEZBTeIiIiJqPwFhER\nMRmFt4iIiMkovEVERExG4S0iImIyCm8RERGTUXiLiIiYjMJbRETEZBTeIiIiJqPwFhERMRmFt4iI\niMkovEVERExG4S0iImIyCm8RERGTUXiLiIiYjMJbRETEZBTeIiIiJqPwFhERMRmFt4iIiMkovEVE\nRExG4S0iImIyCm8RERGTUXiLiIiYjMJbRETEZBTeIiIiJqPwFhERMRmFt4iIiMkovEVERExG4S0i\nImIyCm8RERGTUXiLiIiYTJbC+9ixY3To0IGWLVsCMHfuXA4dOuTQwkRERCRjWQrvsWPHMmHCBHx9\nfQFo3bo1EydOdGhhIiIikjGXLI3k4kKFChVs3aVLl8bF5e6TTpgwgUOHDmGxWBg+fDhVq1a1Dfvj\njz8YMGAAN2/epFKlSowdO/YflC8iIvLoydKet4uLCxEREVgsFgB++OEHDMPIdJo9e/Zw9uxZVq1a\nRUhICCEhIXbDJ02aRM+ePVmzZg3Ozs78/vvv/3AVREREHi1Z2vMeOnQovXv35vTp09SqVYuiRYsy\nZcqUTKfZuXMnzZo1A6Bs2bJcvXoVq9WKu7s7qamp7N+/n+nTpwMQHBx8j6shIiLy6MhSeHt5ebF+\n/XpiYmJwdXXF3d39rtNER0dTuXJlW7e3tzdRUVG4u7sTExNDvnz5mDhxIuHh4dSuXZuBAwfepQY3\nXFycs1JujuTr6/GgS5AcRt8p81BbmcP9bKcshfegQYNYvHgx3t7e/3hBtx9mNwyDixcv0r17d4oW\nLcrrr7/O999/T6NGje44fWxs/D9ettn5+noQFRX3oMuQHEbfKfNQW5mDI9rpThsEWQrvUqVKMWTI\nEGrUqEGuXLls/Tt16nTHafz8/IiOjrZ1X7p0yXa1upeXF0WKFKFEiRIA1K9fn+PHj2ca3iIiIpIm\nSxes3bx5E2dnZ8LCwti/f7/tv8w0aNCATZs2ARAeHo6fn5/tcLuLiwvFixfnzJkztuGlS5e+h9UQ\nERF5dGRpz/vWPd1XrlzBYrHg6el512lq1qxJ5cqVCQwMxGKxEBwcTGhoKB4eHjRv3pzhw4czbNgw\nDMMgICCAJk2a3NuaiIiIPCKyFN4HDhxgyJAhXL9+HcMwKFCgAO+//z6PP/54ptMNGjTIrvv2e8VL\nlizJihUr/kHJIiIij7Yshfe0adOYN28eAQEBAPzyyy+EhISwbNkyhxYnIiIi6WXpnLeTk5MtuAEq\nVaqEs/Oje9uWiIjIg5Tl8N68eTNWqxWr1cqGDRsU3iIiIg9Ilg6bjxkzhnHjxjFixAicnJyoVq0a\nY8aMcXRtIiIikoEs3+c9Y8YMPDzSbhaPjo7Gx8fHoYWJiIhIxrJ02HzZsmUMHTrU1j1gwACWLl3q\nsKJERETkzrIU3uvWrWPWrFm27k8++YSvvvrKYUWJiIjInWUpvFNSUuze322xWO76SlARERFxjCyd\n827SpAmBgYHUqlWL1NRUdu3axbPPPuvo2kRERCQDWQrv3r17U7duXcLCwmyPOq1evbqjaxMREZEM\nZOmw+dWrV/H09KRnz56ULVuW7du3ExUV5ejaREREJANZCu/Bgwdz6dIlzpw5w5QpUyhQoAAjRoxw\ndG0iIiKSgSyFd0JCAg0aNGDjxo28/PLLvPzyy9y8edPRtYmIiEgGshzeMTExbNq0iUaNGmEYBlev\nXnV0bSIiIpKBLIV3u3btePbZZ3niiScoXLgwc+fOpV69eo6uTURERDKQpavNe/ToQY8ePWzd3bt3\nJ3/+/A4rSkRERO4sS3vef6XgFhEReXD+UXiLiIjIg6PwFhERMZkshffJkyfp3r07NWrUoFatWrzy\nyiucPXvW0bWJiIhIBrIU3uPGjaNnz55s376dH3/8kcDAQEaPHu3g0kRERCQjWQpvwzBo1KgRbm5u\n5MuXj+bNm5OSkuLo2kRERCQDWQrvmzdvEh4ebusOCwtTeIuIiDwgWbrPe+jQoQwcOJCYmBgAfH19\nmTx5skMLExERkYxlKbwLFy7Mxo0biYuLw2Kx4O7u7ui6RERE5A6ydNh80KBBAHh4eCi4RUREHrAs\n7XmXKlWKIUOGUKNGDXLlymXr36lTJ4cVJiIiIhnLUnjfvHkTZ2dnwsLC7PorvEVERO6/LIX3xIkT\nOXPmDKVKlQLgl19+oVKlSo6sS0RERO4gS+e8P/jgAxYsWGDrXrhwIdOmTXNYUSIiInJnWQrv3bt3\nM3HiRFv3jBkz2Ldvn8OKEhERkTvL8kNakpKSbN3Xr18nOTnZYUWJiIjInWXpnHdgYCCtW7emSpUq\npKamcvjwYfr06ePo2kRERCQDWQrvzp0706BBAw4fPozFYuHdd9+lcOHCjq5NREREMpBpeP/www80\nbNiQNWvW2PXfvn07oFvFREREHoRMw/vXX3+lYcOG7N+/P8PhCm8REZH7L9Pwfv311wHsrjQXERGR\nBytL57zXrl3L559/TlxcHIZh2Ppv2bLFYYWJiIhIxrIU3vPmzWP8+PH4+/s7uh4RERG5iyyFd5ky\nZahbt66jaxEREZEsyPJ93j179qRatWo4Ozvb+utebxERkfsvS09Ymzx5MoUKFcIwDJKTk23/iYiI\nyP2XpT1vX19fXXEuIiLykMhSeD/99NOEhoZSo0YNXFz+nKR48eIOK0xEREQylqXwXrFiRbp+FotF\nt4qJiIg8AFkK761bt95x2Nq1a2nfvn22FSQiIiKZy9IFa5kJDQ3NjjpEREQki+45vG9/4pqIiIg4\n3j2Ht8ViyY46REREJIvuObxFRETk/nJoeE+YMIEuXboQGBhIWFhYhuNMmzaNoKAgR5YhIiKSo9xz\neLu7u2fYf8+ePZw9e5ZVq1YREhJCSEhIunFOnDjB3r1777UEERGRR8o/Du/JkycDaW8cy8jOnTtp\n1qwZAGXLluXq1atYrVa7cSZNmkT//v3/aQkiIiKPpH8c3uHh4ZkOj46OxsvLy9bt7e1NVFSUrTs0\nNJS6detStGjRf1qCiIjIIynTh7Q0bNgww6vJDcMgNjb2by3o9lvKrly5QmhoKJ9++ikXL17M0vRe\nXm64uDjffcQcytfX40GXIDmMvlPmobYyh/vZTpmGd61atahduzYNGza0628YBoMGDcp0xn5+fkRH\nR9u6L126hK+vLwC7du0iJiaGl19+maSkJM6dO8eECRMYPnz4HecXGxt/15XJqXx9PYiKinvQZUgO\no++UeaitzMER7XSnDYJMD5uPGzeO3bt3U6BAAYoWLWr7r1ixYuTKlSvTBTZo0IBNmzYBaYfY/fz8\nbBe3tWzZkg0bNrB69WrmzJlD5cqVMw1uERER+VOme95Wq5WZM2dy4cIF8uXLZzfsk08+yXTGNWvW\npHLlygQGBmKxWAgODiY0NBQPDw+aN29+75WLiIg8ojIN7zfffJOVK1cyePBgFi9ebHfe2tn57uef\n/3povUKFCunGKVasGEuWLMlqvSIiIo+8TMO7ePHiVK9endTUVCpVqmTrbxgGFouFo0ePOrxAERER\nsZdpeM+cOROAkSNHMn78+PtSkIiIiGQuS/d5K7hFREQeHnoxiYiIiMkovEVERExG4S0iImIyCm8R\nERGTUXiLiIiYjMJbRETEZBTeIiIiJqPwFhERMRmFt4iIiMkovEVERExG4S0iImIyCm8RERGTUXiL\niIiYjMJbRETEZBTeIiIiJqPwFhERMRmFt4iIiMkovEVERExG4S0iImIyCm8RERGTUXiLiIiYjMJb\nRETEZBTeIiIiJqPwFhERMRmFt4iIiMkovEVERExG4S0iImIyCm8RERGTUXiLiIiYjMJbRETEZBTe\nIiIiJqPwFhERMRmFt4iIiMkovEVERExG4S0iImIyCm8RERGTUXiLiIiYjMJbRETEZBTeIiIiJqPw\nFhERMRmFt4iIiMkovEVERExG4S0iImIyCm8RERGTUXiLiIiYjMJbRETEZBTeIiIiJqPwFhERMRkX\nR858woQJHDp0CIvFwvDhw6latapt2K5du5g+fTpOTk6ULl2akJAQnJy0LSEiInI3DkvLPXv2cPbs\nWVatWkVISAghISF2w0eNGsWsWbNYuXIl169f56effnJUKSIiIjmKw8J7586dNGvWDICyZcty9epV\nrFarbXhoaCj+/v4AeHt7Exsb66hSREREchSHHTaPjo6mcuXKtm5vb2+ioqJwd3cHsP3/0qVLbN++\nnb59+2Y6Py8vN1xcnB1V7kPP19fjQZcgOYy+U+ahtjKH+9lODj3nfTvDMNL1u3z5Mr169SI4OBgv\nL69Mp4+NjXdUaQ89X18PoqLiHnQZksPoO2UeaitzcEQ73WmDwGGHzf38/IiOjrZ1X7p0CV9fX1u3\n1Wrltddeo1+/fjz11FOOKkNERCTHcVh4N2jQgE2bNgEQHh6On5+f7VA5wKRJk+jRowfPPPOMo0oQ\nERHJkRx22LxmzZpUrlyZwMBALBYLwcHBhIaG4uHhwVNPPcXatWs5e/Ysa9asAaBt27Z06dLFUeWI\niIjkGA495z1o0CC77goVKtj+PnLkiCMXLSIikmPpqSgiIiImo/AWERExGYW3iIiIySi8RURETEbh\nLSIiYjIKbxEREZNReIuIiJiMwltERMRkFN4iIiImo/AWERExGYW3iIiIySi8RURETEbhfZv9+/fS\ns+fLBAZ2oF+/3ly6dDHdOIZhsHz5Yho2rMehQwfthn333SaCgl6ka9cOjBgxGKvVaht2/nwkPXu+\nTN++ve2miYyMoG/fNwkMfIEePbry22/HclytIiKSvRTe/5OQkEBw8HCGDn2PlStDadDgGaZOnZhu\nvKlTJxIRcQ4vL2+7/hcuXGDGjPd5//1ZrFgRir9/ERYunAvAuXNnGDKkHxUqVEo3vzFjRvLMM41Y\nufI/9O79DqNGvYthGDmmVhERyX4K7//Zv38vRYoUpXz5tNeWtmnzHHv27CI+/rrdeK1atWXo0JG4\nuNi/TfXnn7+nVq06+Pv7A9C27fNs27YFAFfX3MycOZ8qVaraTXP9upWjR8Np3fo5AOrVq4+Liwsn\nTvyWY2oVEZHsp/D+n4iIcxQtWszW7ebmhqenJ5GREXbj/TXUbp++SJE/py9atBixsTFcu3YNf//C\n+Pj4pJvGYrEAYBiptn558+ZNt0wz1yoiItlP4f0/N24k4urqatfP1TUPCQmJWZo+MTGR3Llz3zat\nKxaLhcTEhDtO4+aWj0qVqrBy5TIMw2Dv3t2cOnWSpKSkHFOriIhkP4X3/+TJkyddEN24kYibW94s\nTZ83b15u3Lhx27Q3MAyDvHndMp0uOHg8hw8fomvXjmzd+h1Vq1bH3d0jx9QqIiLZz+XuozwaSpYs\nxZYt39q6rVYrcXHXKFasRJamL1GiFAcPHrB1R0ZGULCgDx4emYdb0aLF+OCDubbuF198nrJlH8sx\ntYqISPbTnvf/1KxZm4sXL9huqVq1ahlPPvkUefNmbW/26acbsn//Hs6dO2ObvlmzFnedbujQ/nz/\nfdrFYhs3fk2hQv74+xfOMbWKiEj2sxgmudcnKirO4cs4cGAfM2dOIzExgaJFizNiRDCpqakMGNCH\nJUtWAxAU9CIpKSmcPx+Jj48vuXPnZuTIMVSqVIUtW77lk08WkJKSQkBABYYNew83NzfWrl3D6tUr\nuH7dyvXr1/HzK0TFipV5772xhIUdZMqUCdy4cQN/f39GjhxDoUL+dnX5+nqkW/+HtVZH8JuX3+HL\nyDajTfHPCYBLl7L/35TayjHUVuZoK0e0k69vxkdEFd4mkFF4P0r0I+MYCgS1lWmYpK3uZ3jrsLmI\niIjJPLIXrJlvq9McV3U7YstTRETsac9bRETEZBTeIiIiJqPwFhERMRmFt4iIiMkovEVERExG4S0i\nImIyCm8RERGTUXiLiIiYjMJbRETEZBTeIiIiJqPwFhERMRmFt4iIiMkovEVERExG4S0iImIyCm8R\nERGTUXiLiIiYjMJbRETEZBTeIiIiJqPwFhERMRmFt4iIiMkovEVERExG4S0iImIyCm8RERGTUXiL\niIiYjMJbRETEZBTeIiIiJuPQ8J4wYQJdunQhMDCQsLAwu2E7duygU6dOdOnShblz5zqyDBERkRzF\nYeG9Z88ezp49y6pVqwgJCSEkJMRu+Pjx45k9ezYrVqxg+/btnDhxwlGliIiI5CgOC++dO3fSrFkz\nAMqWLcvVq1exWq0ARERE4OnpSeHChXFycqJhw4bs3LnTUaWIiIjkKA4L7+joaLy8vGzd3t7eREVF\nARAVFYW3t3eGw0RERCRzLvdrQYZh3NP0vr4e2VRJGiP43uq5r4IfdAF/R/a2E6itHEdtZR5qK3PI\n/na6E4ftefv5+REdHW3rvnTpEr6+vhkOu3jxIn5+fo4qRUREJEdxWHg3aNCATZs2ARAeHo6fnx/u\n7u4AFCtWDKvVSmRkJMnJyWzbto0GDRo4qhQREZEcxWLc6/HsTEydOpV9+/ZhsVgIDg7ml19+wcPD\ng+bNm7N3716mTp0KwLPPPssrr7ziqDJERERyFIeGt4iIiGQ/PWFNRETEZBTeIiIiJqPwvg8iIyOp\nUaMGQUFBdOvWjR49euihNPfZ2bNn6dWrF507d6Zz58707duXmJgYhyxr4cKF/Pe///1b00RGRlKx\nYkWOHTtm6xcaGkpoaCgATZo04aWXXiIoKIiOHTuyYsWKbK05pwkNDWXy5Mm27qx8vkuWLLEbf9iw\nYfevYBOIjIykfPnyHDx40K5/x44dGTZsGMOGDWPbtm3ppqtcuTJBQUEEBQXRuXNnu+9uWFgYQUFB\ndOnShQ4dOjBnzhwMw2D37t28884791xzaGgo3377LQC9evWie/fu/Pjjjyxfvvye5/2g3bf7vB91\npUuXtv04nDt3jl69ejF9+nQqVKjwgCvL+VJSUnj77bcZNWoUtWvXBtICNiQkhGnTpmX78l5//fV/\nNN1jjz3GtGnTWLRoUYbDFy1aRL58+YiPj6dZs2a8+OKLODs730upj5TMPt+CBQuyevVqXnjhBdtd\nMZJe8eLF+eqrr6hevTqQtlF87dq1TKdxd3e3/fYlJSXxwgsv8Mwzz+Dp6cngwYOZPXs2AQEB3Lx5\nk379+vHFF19QsmTJbKm3Q4cOtr/379/P3r17s2W+DwOF9wNQokQJevXqxfvvv09sbKxt679Dhw7M\nmjWLOXPm4O3tTXh4ODExMbz22muEhoYSGxvL0qVL+fbbb9m7dy+xsbEcP36c/v3789VXX3Hy5Emm\nTp3K5s2bKVWqFJ07dwagdevWLFu2zO6Jd4+S7du3U65cOVtwA7z66qsYhsGxY8cYM2YMLi4uODk5\nMXPmTKxWK++88066djlz5gwzZswgT548FCxYkKlTp7J79+50/d577z1atGhBnTp1GDhwIPHx8SQm\nJvLee+9RtWpVmjdvTpcuXdi2bRtJSUl8+umnQNoeSkJCAjt37qR+/fp3XJ+rV6/i5eWl4M6iadOm\nkTdv3kw/3zx58tC+fXs+/vhj+vbt+4AqffhVq1aNHTt2kJKSgrOzM19//TUNGjQgMTExS9O7uroS\nEBBAREQEP/74I02bNiUgIACAXLlyMXnyZPLmzcu+ffts03zyySds2rSJ1NRUGjZsSJ8+ffjll18Y\nM2YMrq6uuLq68sEHHxAZGZmu3+eff46XlxeRkZHEx8fz6quv0rp1a44fP87QoUNZtmwZ69evx8nJ\niWbNmtGzZ09mz55NREQEkZGRLFmy5KH9d6bD5g9IlSpVMn0Zi4uLC59//jkBAQH897//5bPPPiMg\nIIDdu3cDcObMGT788EPeeOMNFixYwNy5c3n99df56quveP755/nmm28AOHHiBMWLF39kgxvg1KlT\nlC9f3q6fk5MTzs7OXL58mffee48lS5ZQs2ZN1q9ff8f5LF26lGHDhrF06VLatGnDlStXMux3S1RU\nFJ07d2bJkiUMGDDAtseXkpJCmTJlWLZsGcWKFWPXrl22afr378+MGTMyfCLha6+9xssvv8wLL7xA\n79697/VjeSR88803/PHHHzz33HNA5p/vrQ0qPar5znLlykW1atVsv0NbtmyhYcOGWZ7+ypUrHD16\nlICAAE6dOkXFihXthru7u2cYlsuXL2f16tWEhoZitVoJDQ2la9euLFmyhFdffZWoqKgM+90ybNgw\n3N3d+eijj2z9IiIi2LhxIytWrGDZsmVs3ryZ33//HYCbN2+yfPnyhza4QXveD8z169cz/WJUrVoV\nSHsaXZkyZQDw8fEhLi4OSAt/i8WCr68v5cuXx9nZGR8fHw4cOEBAQADXrl0jJiaGLVu20K5dO8ev\n0EPMycmJ5ORkW/ebb76J1WrlwoULzJ49m6lTp5KYmMilS5cy/axatmxJcHAw7dq1o02bNvj6+mbY\n7xYfHx/mzZvHxx9/TFJSEm5ubrZht44C+Pv729oUoFSpUlSqVIkNGzakW/6tw+ZWq5V//etfVKhQ\ngbJly97TZ5OTHT9+nM2bN7NhwwbbD3lmn6+LiwtvvPEGs2fP/senPh4FLVu25KuvvsLHx4dChQrZ\nfa8zYrVaCQoKAsBisTBkyBC8vb2xWCykpKTcdXl58uShW7duuLi4EBsby5UrV2jatCmjR4/mzJkz\ntG7dmrJly2bYLzOHDx/m7NmzdO/eHUj7TT5//jzw5+/vw0x73g/IkSNHqFevnl2/2wPm9mC//e9b\newwuLn9ud93+963hbdu2ZfPmzezcuZOmTZtmb/EmU65cOQ4fPmzr/vDDD1myZAkpKSmEhITQvXt3\nli5dSpcuXYC0H5jb3WqX9u3bs3jxYry8vHjzzTc5efJkhv1u+fzzzylUqBArVqxg9OjRdvPMqE1v\neeutt1i4cKHd9+F27u7u1K1bN92FQ2Lv/PnzlCtXjo0bN9r1z+zzbdWqFb/99htnzpy5T1WaT/36\n9dm9ezdff/01LVq0uOv4t855L1myhMWLF9OkSRMAypQpY/fvEiAmJsYWoJDWhp999hkfffQRS5Ys\noWjRorYa1qxZQ5kyZRg2bBi7du3KsF9mcuXKRaNGjWy1rV+/njp16tiGPewU3g/AuXPn+Oyzz+jT\npw+XL1/GMAyioqKIiIjItmW0bduW0NBQfH19yZs3b7bN14yeeOIJLly4wNatW239wsPDuX79Ohcv\nXqREiRIkJSXxww8/cPPmTdzd3TNsl7lz5+Li4kKXLl1o3bo1J0+ezLDfLbGxsZQoUQKA7777jps3\nb2apXh8fH5o1a8bKlYr3SWsAAAJdSURBVCszHG4YBocPH6Z06dL/9CN5JDRq1IgJEyYwb948Ll++\nbOt/t8+3f//+TJ8+/X6VaTqurq7UqVOHL7/80hbE/0S7du34/vvvCQsLA9IuZhs9ejQ7duywjRMb\nG4u3tzf58uUjPDyc8+fPc/PmTZYuXcqVK1d47rnn6NGjB0ePHs2wX2YqV67M7t27SUhIwDAMxo8f\nn+Vz9w8DHTa/T06fPk1QUBBJSUmkpKQwatQoihYtypNPPknHjh2pUKFCuvM/98LHxwc3Nzfatm2b\nbfM0K4vFwkf/394dsygOhGEc/7NBEUNSiFXAyspWC0sbCxHESggExQStBK3EUkxjZycWWfwE2llY\n+Dls/A7phJRX7bGLy3Fwx0LC8yunGt5AnplJZub9nTAM2e/35HI5isUih8OBx+PBbDajUqkwHA4J\nw5But/vtc3EcB9/3sW0b27bxfZ/n8/nS9jFI6Pf7rFYrrtcrnudxuVw4n89/1ecgCF62g02nUwzD\nIEkSWq0W9Xr9/xYqg0qlEvP5nCiKvvxF/l19PzSbTcrl8k91MZU6nQ5xHGNZX2/R2u12HI9HAKrV\n6suK02emaRJFEev1miRJMAyDXq/HYDD4/U29Vqthmiau69JoNHBdl81mQxAELBYLLMsin8+z3W65\n3+8vbX/aUuk4DqPRCM/zMAyDdrtNoVD49+L8EB2PmlFxHDOZTDidTry9aYFFRCRL9FbPoNvtxng8\nZrlcKrhFRDJIM28REZGU0bRMREQkZRTeIiIiKaPwFhERSRmFt4iISMoovEVERFJG4S0iIpIyvwA4\n5dzbS1LbGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a22d61358>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 4\n",
    "f1_default = list(f1_micro_default.values())\n",
    "\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.4       # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, f1_default, width, color='g')\n",
    "\n",
    "f1_optimized = time_optimized = list(f1_micro_optimized.values())\n",
    "\n",
    "rects2 = ax.bar(ind + width, f1_optimized, width, color='b')\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('f1_micro score')\n",
    "ax.set_title('F1 micro score default vs optimized')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(list(f1_micro_default.keys()))\n",
    "\n",
    "ax.legend((rects1[0], rects2[0]), ('default', 'optimized'))\n",
    "\n",
    "# Turn on the grid\n",
    "#ax.minorticks_on()\n",
    "#ax.grid(which='major', linestyle='-', linewidth='0.5', color='red')\n",
    "# Customize the minor grid\n",
    "#ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.01*height,\n",
    "                \"{:.4f}\".format(height),\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "X2OGjSvj__E6",
    "outputId": "e8e9b6f1-2145-452b-b09c-f89af9c8e3ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 macro scores:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dummy</th>\n",
       "      <th>GaussianNB</th>\n",
       "      <th>MLPClassifier</th>\n",
       "      <th>kNN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>default</th>\n",
       "      <td>0.102097</td>\n",
       "      <td>0.87578</td>\n",
       "      <td>0.951618</td>\n",
       "      <td>0.819753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>optimized</th>\n",
       "      <td>0.102097</td>\n",
       "      <td>0.87578</td>\n",
       "      <td>0.954028</td>\n",
       "      <td>0.875220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Dummy  GaussianNB  MLPClassifier       kNN\n",
       "default    0.102097     0.87578       0.951618  0.819753\n",
       "optimized  0.102097     0.87578       0.954028  0.875220"
      ]
     },
     "execution_count": 243,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores = [f1_macro_default, f1_macro_optimized]\n",
    "print(\"F1 macro scores:\")\n",
    "pd.DataFrame(f1_scores, index=['default', 'optimized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "colab_type": "code",
    "id": "MoTyPYUUuXX0",
    "outputId": "c92a68c3-e452-4d72-d6ce-3d47f119dcf2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFZCAYAAACxGqelAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a22cd4828>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 4\n",
    "f1_default = list(f1_macro_default.values())\n",
    "\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.4       # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(ind, f1_default, width, color='g')\n",
    "\n",
    "f1_optimized = time_optimized = list(f1_macro_optimized.values())\n",
    "\n",
    "rects2 = ax.bar(ind + width, f1_optimized, width, color='b')\n",
    "\n",
    "# add some text for labels, title and axes ticks\n",
    "ax.set_ylabel('f1_macro score')\n",
    "ax.set_title('F1 macro score default vs optimized')\n",
    "ax.set_xticks(ind + width / 2)\n",
    "ax.set_xticklabels(list(f1_macro_default.keys()))\n",
    "\n",
    "ax.legend((rects1[0], rects2[0]), ('default', 'optimized'))\n",
    "\n",
    "# Turn on the grid\n",
    "#ax.minorticks_on()\n",
    "#ax.grid(which='major', linestyle='-', linewidth='0.5', color='red')\n",
    "# Customize the minor grid\n",
    "#ax.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"\n",
    "    Attach a text label above each bar displaying its height\n",
    "    \"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width()/2., 1.01*height,\n",
    "                \"{:.4f}\".format(height),\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rNl-uQJ20g0k"
   },
   "source": [
    "Here we can clearly see, that the best classifier for our dataset is MLPClassifier. Althrough, the next better is GaussianNB, there is quite a difference at the results between then. Something important to note, is that no matter how we tried to manipulate our data in order Optimize the GaussianNB, we couldn't achieve a better score than with the initila data. Applying a Variance Theshold (even 0), didn't make any differnce and apllying PCA, even reduced our score, due to significant loss of information.\n",
    "\n",
    "On the other hand, there was some room for a small optimizations in the MLP Classifier. However, due to the fact that the default solver is adam and that the best solver for our dataset was also Adam, there was only a small increase in our score, by optimizing the rest of the parameters (activation function, hidden_layers_sizes, max_iters and alpha). Of course the optimization of these parameters increased the time needed to fit (as shown in the previous diagram).\n",
    "\n",
    "Finally, it is important to note, that we always have an average 0.1 error in our f1-scores in each classifier. Having restarted and rerun the whole notebook multiple times, we achieved for the optimized kNN classifier as highest score 0.90  and as lowest score 0.88. We also achieved a highest 0.97 and lowest 0.95 with MLPClassifier. However, whenever we received the lowest score in one classifier, we also received the lowest score at the others classifiers too. And whenever we received the highest score in one classifier we also received the highest scores for the others, too (both defaults and optimized classifiers). Since this behavor is found in the same way in all the classifiers that we tested, it is probably a result of the way the data are splitted into train and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0vBDTHMhFgr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "A61_B08-final.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
